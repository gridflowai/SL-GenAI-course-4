{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5506f16f-683d-4ff9-b921-4600c3b00de0",
   "metadata": {},
   "source": [
    "#### Basic LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2f8e98c3-87b2-403b-b36a-b09ca7a0d545",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356a7fd2-fb25-4c69-ae3c-f8dde2fd12e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template\n",
    "prompt = PromptTemplate.from_template(\"What is the capital of {country}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9862127f-bc19-4c4f-9157-fdd690f11f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupe\\AppData\\Local\\Temp\\ipykernel_28296\\2838644879.py:4: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  chain = LLMChain(llm   = llm,\n"
     ]
    }
   ],
   "source": [
    "# Initialize the LLM and chain\n",
    "llm   = ChatOpenAI()\n",
    "\n",
    "chain = LLMChain(llm   = llm, \n",
    "                 prompt= prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "353b23ef-ad26-4a50-8d23-85fdf7d18440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'France', 'text': 'The capital of France is Paris.'}\n"
     ]
    }
   ],
   "source": [
    "# Run the chain\n",
    "result = chain.invoke({\"country\": \"France\"})\n",
    "print(result)  # Output should be \"Paris\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd1cbb-a361-4a2e-9a7a-49a49521ff15",
   "metadata": {},
   "source": [
    "#### SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08b07ea5-307d-4c11-bf46-3b46cb8573b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "106c321e-9a5d-422d-aaaa-c02ee18caf9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model = 'gpt-3.5-turbo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f891827a-25df-4477-a2f5-85b335848ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What is the best name to describe \\\n",
    "    a company that makes {product}?\"\n",
    ")\n",
    "\n",
    "# Chain 1\n",
    "chain_one = LLMChain(llm=llm, prompt=first_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d613d721-fd71-4877-9be2-afdbcfe91da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 2\n",
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a 20 words description for the following \\\n",
    "    company:{company_name}\"\n",
    ")\n",
    "# chain 2\n",
    "chain_two = LLMChain(llm=llm, prompt=second_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cde30341-0ea4-4681-97f4-488f71b1b56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_simple_chain = SimpleSequentialChain(chains=[chain_one, chain_two],\n",
    "                                             verbose=True\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db1aaf03-1ce5-4d37-aed1-4d7fbd9dbede",
   "metadata": {},
   "outputs": [],
   "source": [
    "product = \"fitbit\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0343e33e-bc7c-460b-8427-756f84657553",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupe\\AppData\\Local\\Temp\\ipykernel_28296\\228193363.py:1: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  overall_simple_chain.run(product)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3m\"FitTech\"\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3mFitTech is a leading provider of innovative fitness technology solutions, offering cutting-edge products and services for health and wellness enthusiasts.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FitTech is a leading provider of innovative fitness technology solutions, offering cutting-edge products and services for health and wellness enthusiasts.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_simple_chain.run(product)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee83f258-ef8e-442a-91d9-15adb2ffdb7a",
   "metadata": {},
   "source": [
    "-----------------------\n",
    "#### Sequential Chain\n",
    "\n",
    "- A SequentialChain allows you to run multiple chains in sequence, where the output of one chain is used as the input to the next.\n",
    "- ---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de6f5de7-4798-43a7-b0ca-589cb9026b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.sequential import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "522ba088-500c-4991-815a-a4a5b1652489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt templates\n",
    "prompt1 = PromptTemplate.from_template(\"What is the capital of {country}?\")\n",
    "prompt2 = PromptTemplate.from_template(\"Describe the main attractions in {city}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "969873a0-303a-48e2-97ac-779484c8b384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "00964cdf-86a5-4933-8159-28250b7212c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual chains with explicit output\n",
    "chain1 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt1, \n",
    "                  output_key=\"city\")               # Sets \"city\" as output for chain1\n",
    "\n",
    "chain2 = LLMChain(llm       = llm, \n",
    "                  prompt    = prompt2, \n",
    "                  output_key= \"city_description\")  # Sets \"city_description\" as output for chain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "81b29561-fca6-4db3-b3c8-145066a6fd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the SequentialChain\n",
    "sequential_chain = SequentialChain(\n",
    "    chains           = [chain1, chain2],\n",
    "    input_variables  = [\"country\"],          # Input to the first chain\n",
    "    output_variables = [\"city_description\"]  # Output from the last chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a304f5-1be5-4f62-8cf3-216120a3f2ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokyo, the bustling capital city of Japan, is a vibrant metropolis that offers a wide range of attractions for visitors to enjoy. Some of the main attractions in Tokyo include:\n",
      "\n",
      "1. Tokyo Tower: A symbol of the city, this iconic red and white tower offers panoramic views of the city from its observation decks.\n",
      "\n",
      "2. Shibuya Crossing: One of the busiest pedestrian crossings in the world, this bustling intersection in Shibuya is a must-see for visitors looking to experience the energy of Tokyo.\n",
      "\n",
      "3. Senso-ji Temple: Located in the historic Asakusa district, this ancient Buddhist temple is a popular destination for tourists and locals alike.\n",
      "\n",
      "4. Meiji Shrine: Nestled in the heart of bustling Shibuya, this serene Shinto shrine is a peaceful oasis in the midst of the city.\n",
      "\n",
      "5. Tsukiji Fish Market: One of the largest and most famous fish markets in the world, Tsukiji offers visitors the chance to sample some of the freshest seafood in Tokyo.\n",
      "\n",
      "6. Tokyo Disneyland and DisneySea: These two theme parks offer a magical escape for visitors of all ages, with attractions, shows, and parades inspired by Disney characters and stories.\n",
      "\n",
      "7. Harajuku: Known for its vibrant street fashion and quirky shops, this trendy neighborhood is a must-visit for fashion enthusiasts and trendsetters.\n",
      "\n",
      "8. Akihabara: Tokyo's famous electronics and gaming district, Akihabara is a mecca for tech enthusiasts and anime fans, with countless stores selling the latest gadgets and anime merchandise.\n",
      "\n",
      "9. Tokyo Imperial Palace: The residence of the Emperor of Japan, this sprawling complex is surrounded by beautiful gardens and offers guided tours for visitors to learn about the country's history.\n",
      "\n",
      "10. Odaiba: A futuristic man-made island in Tokyo Bay, Odaiba is home to shopping malls, museums, and entertainment complexes, as well as stunning views of the city skyline.\n"
     ]
    }
   ],
   "source": [
    "# Run the SequentialChain\n",
    "result = sequential_chain.invoke({\"country\": \"Japan\"})\n",
    "print(result[\"city_description\"])  # Should describe attractions in the capital city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c23b7070-86ea-42c1-9c66-5256624547b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0.9, model=llm_model)\n",
    "\n",
    "# prompt template 1: translate to english\n",
    "first_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following review to english:\"\n",
    "    \"\\n\\n{Review}\"\n",
    ")\n",
    "# chain 1: input= Review and output= English_Review\n",
    "chain_one = LLMChain(llm       = llm, \n",
    "                     prompt    = first_prompt, \n",
    "                     output_key= \"English_Review\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4232f914-e9d5-4224-b6ae-beadfec79029",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Can you summarize the following review in 1 sentence:\"\n",
    "    \"\\n\\n{English_Review}\"\n",
    ")\n",
    "# chain 2: input= English_Review and output= summary\n",
    "chain_two = LLMChain(llm       = llm, \n",
    "                     prompt    = second_prompt, \n",
    "                     output_key= \"summary\"\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f4d34cb-5ea3-4ff2-b789-ff5b7d104a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 3: translate to english\n",
    "third_prompt = ChatPromptTemplate.from_template(\n",
    "    \"What language is the following review:\\n\\n{Review}\"\n",
    ")\n",
    "# chain 3: input= Review and output= language\n",
    "chain_three = LLMChain(llm       = llm, \n",
    "                       prompt    = third_prompt,\n",
    "                       output_key= \"language\"\n",
    "                      )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93426cc6-d1f4-4fae-bc27-c1a045bcdefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt template 4: follow up message\n",
    "fourth_prompt = ChatPromptTemplate.from_template(\n",
    "    \"Write a follow up response to the following \"\n",
    "    \"summary in the specified language:\"\n",
    "    \"\\n\\nSummary: {summary}\\n\\nLanguage: {language}\"\n",
    ")\n",
    "# chain 4: input= summary, language and output= followup_message\n",
    "chain_four = LLMChain(llm       = llm, \n",
    "                      prompt    = fourth_prompt,\n",
    "                      output_key= \"followup_message\"\n",
    "                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a28eba76-700b-44b2-9690-c56ef0b74385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overall_chain: input= Review \n",
    "# and output= English_Review,summary, followup_message\n",
    "overall_chain = SequentialChain(\n",
    "    chains          = [chain_one, chain_two, chain_three, chain_four],\n",
    "    input_variables = [\"Review\"],\n",
    "    output_variables= [\"English_Review\", \"summary\",\"followup_message\"],\n",
    "    verbose         = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93f5e782-9ba9-4cf0-9f18-53a2ba603fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "review = '''\n",
    "বাংলাদেশ একটি সমৃদ্ধ ইতিহাস ও সংস্কৃতির দেশ। এই দেশে রয়েছে প্রাচীন স্থাপত্য, নদী, সবুজ প্রকৃতি এবং অসংখ্য জাতিগোষ্ঠীর বৈচিত্র্য। \n",
    "বাংলাদেশের মানুষ অতিথিপরায়ণ এবং তারা তাদের ঐতিহ্য ও সংস্কৃতিকে ভালোবাসে। প্রতি বছর এখানে বিভিন্ন ধরনের উৎসব পালন করা হয়, \n",
    "যেমন পহেলা বৈশাখ, ঈদ, দুর্গাপূজা, এবং বিজয় দিবস। এই উৎসবগুলোতে মানুষ একসঙ্গে আনন্দ করে, গান গায়, নাচে এবং খাবার খায়।\n",
    "\n",
    "বাংলাদেশের অন্যতম বড় আকর্ষণ হচ্ছে সুন্দরবন, যা পৃথিবীর বৃহত্তম ম্যানগ্রোভ বন। এখানে রয়েল বেঙ্গল টাইগার, চিত্রা হরিণ, \n",
    "বানর এবং নানা ধরনের বন্যপ্রাণীর বসবাস। সুন্দরবনের প্রকৃতি অত্যন্ত সুন্দর এবং এটি প্রতিবছর হাজার হাজার পর্যটককে আকর্ষণ করে। \n",
    "তাছাড়া কক্সবাজার বিশ্বের দীর্ঘতম সমুদ্রসৈকত হিসাবে পরিচিত। সাদা বালুর সৈকত, নীল পানি, এবং সূর্যাস্তের দৃশ্য প্রতিটি দর্শকের মনে দাগ কাটে।\n",
    "\n",
    "বাংলাদেশের মানুষের জীবনধারা খুবই সরল এবং প্রকৃতির সাথে গভীরভাবে সংযুক্ত। বেশিরভাগ মানুষ গ্রামাঞ্চলে বাস করে এবং তারা \n",
    "কৃষিকাজে ব্যস্ত থাকে। ধান, পাট, চা, এবং মাছ বাংলাদেশের প্রধান পণ্য। দেশটি ধীরে ধীরে শিল্প এবং প্রযুক্তিতে এগিয়ে যাচ্ছে এবং এশিয়ার \n",
    "একটি গুরুত্বপূর্ণ অর্থনৈতিক কেন্দ্রে পরিণত হচ্ছে।\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "df32b716-5cbb-40f2-b7f9-fd2904112bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Review': '\\nবাংলাদেশ একটি সমৃদ্ধ ইতিহাস ও সংস্কৃতির দেশ। এই দেশে রয়েছে প্রাচীন স্থাপত্য, নদী, সবুজ প্রকৃতি এবং অসংখ্য জাতিগোষ্ঠীর বৈচিত্র্য। \\nবাংলাদেশের মানুষ অতিথিপরায়ণ এবং তারা তাদের ঐতিহ্য ও সংস্কৃতিকে ভালোবাসে। প্রতি বছর এখানে বিভিন্ন ধরনের উৎসব পালন করা হয়, \\nযেমন পহেলা বৈশাখ, ঈদ, দুর্গাপূজা, এবং বিজয় দিবস। এই উৎসবগুলোতে মানুষ একসঙ্গে আনন্দ করে, গান গায়, নাচে এবং খাবার খায়।\\n\\nবাংলাদেশের অন্যতম বড় আকর্ষণ হচ্ছে সুন্দরবন, যা পৃথিবীর বৃহত্তম ম্যানগ্রোভ বন। এখানে রয়েল বেঙ্গল টাইগার, চিত্রা হরিণ, \\nবানর এবং নানা ধরনের বন্যপ্রাণীর বসবাস। সুন্দরবনের প্রকৃতি অত্যন্ত সুন্দর এবং এটি প্রতিবছর হাজার হাজার পর্যটককে আকর্ষণ করে। \\nতাছাড়া কক্সবাজার বিশ্বের দীর্ঘতম সমুদ্রসৈকত হিসাবে পরিচিত। সাদা বালুর সৈকত, নীল পানি, এবং সূর্যাস্তের দৃশ্য প্রতিটি দর্শকের মনে দাগ কাটে।\\n\\nবাংলাদেশের মানুষের জীবনধারা খুবই সরল এবং প্রকৃতির সাথে গভীরভাবে সংযুক্ত। বেশিরভাগ মানুষ গ্রামাঞ্চলে বাস করে এবং তারা \\nকৃষিকাজে ব্যস্ত থাকে। ধান, পাট, চা, এবং মাছ বাংলাদেশের প্রধান পণ্য। দেশটি ধীরে ধীরে শিল্প এবং প্রযুক্তিতে এগিয়ে যাচ্ছে এবং এশিয়ার \\nএকটি গুরুত্বপূর্ণ অর্থনৈতিক কেন্দ্রে পরিণত হচ্ছে।\\n',\n",
       " 'English_Review': \"Bangladesh is a country rich in history and culture. It has ancient architecture, rivers, lush nature, and a diverse range of ethnicities. The people of Bangladesh are hospitable and they love their heritage and culture. Every year, various festivals are celebrated here, such as Pohela Boishakh, Eid, Durga Puja, and Victory Day. During these festivals, people come together to enjoy, sing, dance, and eat.\\n\\nAnother major attraction of Bangladesh is the Sundarbans, the largest mangrove forest in the world. Here, the Royal Bengal Tiger, spotted deer, monkeys, and various other wildlife reside. The nature of the Sundarbans is extremely beautiful and it attracts thousands of tourists every year. Additionally, Cox's Bazar is known as the longest sea beach in the world. The white sandy beach, blue water, and sunset views capture the hearts of every visitor.\\n\\nThe lifestyle of the people in Bangladesh is very simple and deeply connected with nature. Most people live in rural areas and are busy with agricultural work. Rice, jute, tea, and fish are the main products of Bangladesh. The country is gradually progressing in industry and technology and is transforming into an important economic center in Asia.\",\n",
       " 'summary': \"Bangladesh is a country rich in culture and history, known for its diverse ethnicities, ancient architecture, and lush nature, including attractions like the Sundarbans and Cox's Bazar, while its people are hospitable and deeply connected with nature, with a simple lifestyle centered around agriculture and the production of main products like rice, jute, tea, and fish as it progresses in industry and technology.\",\n",
       " 'followup_message': 'সারমেয় এই শোধেরজন্য ধন্যবাদ। বাংলাদেশ সম্পর্কে আপনার বর্ণনাটি খুব সুন্দর ছিল। আমরা কি পর্যবেক্ষণ করতে পারি এই সুন্দর স্থানগুলি? আমাদের সম্পর্কবিধান এবং প্রাকৃতিক সম্পর্ক সম্পর্কে লিখা মনযোগী ছিল। আমাদের মানুষগুলি কতটা প্রাকৃতিক জীবনযাপন করে তা বেশিরভাগ মধ্যে ভালো হয়। ধন্যবাদ।'}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_chain.invoke(review)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40181a2-e0c2-484d-9458-dac395a54281",
   "metadata": {},
   "source": [
    "#### Router chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3efc43ed-5a7c-452d-a469-d1803360153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "physics_template = \"\"\"You are a very smart physics professor. \\\n",
    "You are great at answering questions about physics in a concise\\\n",
    "and easy to understand manner. \\\n",
    "When you don't know the answer to a question you admit\\\n",
    "that you don't know.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "math_template = \"\"\"You are a very good mathematician. \\\n",
    "You are great at answering math questions. \\\n",
    "You are so good because you are able to break down \\\n",
    "hard problems into their component parts, \n",
    "answer the component parts, and then put them together\\\n",
    "to answer the broader question.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "history_template = \"\"\"You are a very good historian. \\\n",
    "You have an excellent knowledge of and understanding of people,\\\n",
    "events and contexts from a range of historical periods. \\\n",
    "You have the ability to think, reflect, debate, discuss and \\\n",
    "evaluate the past. You have a respect for historical evidence\\\n",
    "and the ability to make use of it to support your explanations \\\n",
    "and judgements.\n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\"\n",
    "\n",
    "\n",
    "computerscience_template = \"\"\" You are a successful computer scientist.\\\n",
    "You have a passion for creativity, collaboration,\\\n",
    "forward-thinking, confidence, strong problem-solving capabilities,\\\n",
    "understanding of theories and algorithms, and excellent communication \\\n",
    "skills. You are great at answering coding questions. \\\n",
    "You are so good because you know how to solve a problem by \\\n",
    "describing the solution in imperative steps \\\n",
    "that a machine can easily interpret and you know how to \\\n",
    "choose a solution that has a good balance between \\\n",
    "time complexity and space complexity. \n",
    "\n",
    "Here is a question:\n",
    "{input}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d200b7c-8005-45db-b6ba-c600524e1ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"physics\", \n",
    "        \"description\": \"Good for answering questions about physics\", \n",
    "        \"prompt_template\": physics_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"math\", \n",
    "        \"description\": \"Good for answering math questions\", \n",
    "        \"prompt_template\": math_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"History\", \n",
    "        \"description\": \"Good for answering history questions\", \n",
    "        \"prompt_template\": history_template\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"computer science\", \n",
    "        \"description\": \"Good for answering computer science questions\", \n",
    "        \"prompt_template\": computerscience_template\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "631581f7-8f55-453f-a0bb-10b3f69b4320",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain,RouterOutputParser\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "93dbe632-e40e-47b4-8175-9e3eb2fefc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(temperature=0, model=llm_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12706a57-6e7b-41dc-9804-33219e5f2be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = {}\n",
    "\n",
    "for p_info in prompt_infos:\n",
    "    name            = p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    \n",
    "    prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "    \n",
    "    chain  = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = chain  \n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47b2f32e-70d1-4420-b0e2-d20cd4addcdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'physics: Good for answering questions about physics\\nmath: Good for answering math questions\\nHistory: Good for answering history questions\\ncomputer science: Good for answering computer science questions'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destinations_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6e1e3e15-991f-4163-b704-675860079aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# when LLM cant decide which chain to use\n",
    "default_prompt = ChatPromptTemplate.from_template(\"{input}\")\n",
    "default_chain = LLMChain(llm=llm, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6b760281-91d1-4db2-a2b3-f22f3007fed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "MULTI_PROMPT_ROUTER_TEMPLATE = \"\"\"Given a raw text input to a \n",
    "language model select the model prompt best suited for the input. \n",
    "\n",
    "You will be given the names of the available prompts and a \n",
    "description of what the prompt is best suited for. \n",
    "\n",
    "You may also revise the original input if you think that revising\n",
    "it will ultimately lead to a better response from the language model.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string  name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string  a potentially modified version of the original input\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt \\\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\\\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json)>>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8fda6400-5fc4-4da8-9a11-cfe094226a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given a raw text input to a \n",
      "language model select the model prompt best suited for the input. \n",
      "\n",
      "You will be given the names of the available prompts and a \n",
      "description of what the prompt is best suited for. \n",
      "\n",
      "You may also revise the original input if you think that revising\n",
      "it will ultimately lead to a better response from the language model.\n",
      "\n",
      "<< FORMATTING >>\n",
      "Return a markdown code snippet with a JSON object formatted to look like:\n",
      "```json\n",
      "{{\n",
      "    \"destination\": string  name of the prompt to use or \"DEFAULT\"\n",
      "    \"next_inputs\": string  a potentially modified version of the original input\n",
      "}}\n",
      "```\n",
      "\n",
      "REMEMBER: \"destination\" MUST be one of the candidate prompt names specified below OR it can be \"DEFAULT\" if the input is notwell suited for any of the candidate prompts.\n",
      "REMEMBER: \"next_inputs\" can just be the original input if you don't think any modifications are needed.\n",
      "\n",
      "<< CANDIDATE PROMPTS >>\n",
      "physics: Good for answering questions about physics\n",
      "math: Good for answering math questions\n",
      "History: Good for answering history questions\n",
      "computer science: Good for answering computer science questions\n",
      "\n",
      "<< INPUT >>\n",
      "{input}\n",
      "\n",
      "<< OUTPUT (remember to include the ```json)>>\n"
     ]
    }
   ],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "\n",
    "print(router_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "24e77bf2-d950-4788-b2c0-48a075a9b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_prompt = PromptTemplate(\n",
    "    template       = router_template,\n",
    "    input_variables= [\"input\"],\n",
    "    output_parser  = RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(llm, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f8679085-ca1f-4ecc-94cf-c55349b4bcc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupe\\AppData\\Local\\Temp\\ipykernel_28296\\1422575192.py:1: LangChainDeprecationWarning: Use RunnableLambda to select from multiple prompt templates. See example in API reference: https://api.python.langchain.com/en/latest/chains/langchain.chains.router.multi_prompt.MultiPromptChain.html\n",
      "  chain = MultiPromptChain(router_chain      =router_chain,\n"
     ]
    }
   ],
   "source": [
    "chain = MultiPromptChain(router_chain      =router_chain, \n",
    "                         destination_chains=destination_chains, \n",
    "                         default_chain     =default_chain, \n",
    "                         verbose           =True\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2e122b89-09e5-4bdd-baff-6ed949fff076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "physics: {'input': 'What is black body radiation?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Black body radiation refers to the electromagnetic radiation emitted by a perfect black body, which is an idealized physical body that absorbs all incident electromagnetic radiation and emits radiation at all frequencies. The radiation emitted by a black body depends only on its temperature and follows a specific distribution known as Planck's law. This type of radiation is important in understanding concepts such as thermal radiation and the behavior of objects at different temperatures.\""
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is black body radiation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4a353850-23cd-4b48-985e-144869245b47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "math: {'input': 'what is 2 + 2'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The answer to 2 + 2 is 4.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"what is 2 + 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6ee80b94-438c-4bf1-96cb-440f7e3cb6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "None: {'input': 'What is the capital of Karnatake state in India?'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The capital of Karnataka state in India is Bangalore (Bengaluru).'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What is the capital of Karnatake state in India?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0710edbe-e2cd-4abd-b036-9403529cf2a8",
   "metadata": {},
   "source": [
    "#### Memories with the chains"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afde685a-3b63-493c-bc7b-270c305d9d99",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### Simple Memory Chain\n",
    "- Adding memory to a chain lets it remember parts of the conversation. Here, we use a ConversationChain that retains the entire dialogue context.\n",
    "- -------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8d284bac-5a81-4e30-aec7-e76eb18f110b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.memory import SimpleMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75612811-a081-404c-a758-b3986f49c136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the language model\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7c8bb4ae-4cdd-4dd4-a002-c1d7813a20ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up Simple Memory\n",
    "memory = SimpleMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8b80cef8-9848-4798-b41b-cffb66988a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"Name the Country where Bangalore city is.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0fa4820b-9cc4-4ef7-810d-5c9a45d16a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Access the memory to get previous interactions\n",
    "previous_memory = memory.load_memory_variables({\"input\": user_input})  # This accesses the stored memory directly\n",
    "\n",
    "# Construct the context from previous interactions\n",
    "context = \"\"\n",
    "for key, value in previous_memory.items():\n",
    "    context += f\"User: {key}\\nBot: {value}\\n\"\n",
    "\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a6d0cdbf-c575-4840-b21f-86633d065720",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are a helpful assistant.  \\n    \\n     Here are the previous interactions: \\n     \\n     User: Name the Country where Bangalore city is.\\n     Bot:\\n     ')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a prompt template that uses both current input and memory context\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    f'''You are a helpful assistant.  \n",
    "    \n",
    "     Here are the previous interactions: {context}\n",
    "     \n",
    "     User: {user_input}\n",
    "     Bot:\n",
    "     '''\n",
    ")\n",
    "\n",
    "prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4d5541f6-e4c5-440f-88d3-24a0648468b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLMChain\n",
    "chain = LLMChain(llm   = llm, \n",
    "                 prompt= prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d7b17205-1195-4786-9c15-a289e232f428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '', 'input': 'Name the Country where Bangalore city is.'}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the input for the chain using the current input and memory context\n",
    "combined_input = {\"context\": context.strip(), \"input\": user_input}\n",
    "combined_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6d854b8b-9169-4236-a0dc-8ef965801c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get response from the chain\n",
    "response = chain.invoke(combined_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3a77a020-c50a-45ce-a5bd-4cead8f200b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: {'context': '', 'input': 'Name the Country where Bangalore city is.', 'text': 'Bangalore city is located in the country of India.'}\n"
     ]
    }
   ],
   "source": [
    "# Display the response\n",
    "print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b1849e6d-c922-4db9-ba46-fc2d84ebd77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save user input and bot response to memory\n",
    "memory.save_context({\"input\": user_input}, {\"output\": response})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c51f8b12-3a6f-4a50-bf67-197358af1761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"memories\":{}}'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e2c5cba6-24e5-433c-bc30-9f9b43d37640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f9be588d-92d5-4766-a938-5e468dd0d5a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lc': 1,\n",
       " 'type': 'not_implemented',\n",
       " 'id': ['langchain', 'memory', 'simple', 'SimpleMemory'],\n",
       " 'repr': 'SimpleMemory()'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19f8c2-cbf3-4a8f-9e01-c81849aefb09",
   "metadata": {},
   "source": [
    "#### ConversationBufferMemory\n",
    "- with simple LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a770848b-9558-4f11-b02c-bf61cb46baad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "23d9686a-c7dc-4467-9448-e9080b256c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b930fd28-6fcb-4661-8f67-f8a652e005e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bhupe\\AppData\\Local\\Temp\\ipykernel_28296\\995385594.py:1: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n"
     ]
    }
   ],
   "source": [
    "memory = ConversationBufferMemory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a356d423-8a91-4da6-92f4-4f869e387a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get user input\n",
    "user_input = \"Where is Bangalore?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "7b3c5eef-a75c-47c5-a6dc-62652afaf9c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous memory (initially empty)\n",
    "previous_memory = memory.load_memory_variables({}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e907548f-d5e4-4ba9-aceb-0d48bc2643d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_memory.get('history', \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c2932a52-11f8-42f8-93e9-ea9a2a6aa607",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = previous_memory.get('history', \"\")\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "38505556-242f-423f-8cc5-7dd1b29bf5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a prompt using context and user input\n",
    "prompt_template = PromptTemplate.from_template(\n",
    "    f'''You are a helpful assistant.  \n",
    "    \n",
    "    Here are the previous interactions: {context.strip()}\n",
    "    \n",
    "    User: {user_input}\n",
    "    Bot:\n",
    "    '''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2d8080d6-600b-48e3-8a7f-bc45fd8b4a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an LLMChain\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "1f0cb7c7-ccf6-44c2-a752-9694e169a924",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get response from the chain\n",
    "combined_input = {\"context\": context.strip(), \"input\": user_input}\n",
    "\n",
    "response = chain.invoke(combined_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "73a94ec7-652f-4553-8c8e-b8592887a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bot: {'context': '', 'input': 'Where is Bangalore?', 'text': 'Bangalore is located in the southern part of India, in the state of Karnataka. It is known for being a major hub for technology and innovation.'}\n"
     ]
    }
   ],
   "source": [
    "# Display the response\n",
    "print(\"Bot:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f6d50784-7f65-4a24-87a5-06a9759896b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": user_input}, {\"output\": str(response)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5d883f1e-3c8a-465f-add6-c81e6a071d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"lc\": 1,\n",
      "    \"type\": \"not_implemented\",\n",
      "    \"id\": [\n",
      "        \"langchain\",\n",
      "        \"memory\",\n",
      "        \"buffer\",\n",
      "        \"ConversationBufferMemory\"\n",
      "    ],\n",
      "    \"repr\": \"ConversationBufferMemory(chat_memory=InMemoryChatMessageHistory(messages=[HumanMessage(content='Where is Bangalore?', additional_kwargs={}, response_metadata={}), AIMessage(content=\\\"{'context': '', 'input': 'Where is Bangalore?', 'text': 'Bangalore is located in the southern part of India, in the state of Karnataka. It is known for being a major hub for technology and innovation.'}\\\", additional_kwargs={}, response_metadata={})]))\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Directly pretty-print the dictionary with indentation\n",
    "print(json.dumps(memory.to_json(), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffaa3102-9f14-4792-af33-06be77d0fd37",
   "metadata": {},
   "source": [
    "load from the memory ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d8b2c5b0-94f1-4644-9020-a5d83be703c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load previous memory (initially empty)\n",
    "context = dict(memory.load_memory_variables({}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f47e8391-f596-41fd-a878-31459dd2b9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': \"Human: Where is Bangalore?\\nAI: {'context': '', 'input': 'Where is Bangalore?', 'text': 'Bangalore is located in the southern part of India, in the state of Karnataka. It is known for being a major hub for technology and innovation.'}\"}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7e8b13f1-2936-403e-8a0a-b99c277855a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Human: Where is Bangalore?\\nAI: {'context': '', 'input': 'Where is Bangalore?', 'text': 'Bangalore is located in the southern part of India, in the state of Karnataka. It is known for being a major hub for technology and innovation.'}\""
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "127d52ec-1667-4c0c-8a10-779b8003a870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "InMemoryChatMessageHistory(messages=[HumanMessage(content='Where is Bangalore?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"{'context': '', 'input': 'Where is Bangalore?', 'text': 'Bangalore is located in the southern part of India, in the state of Karnataka. It is known for being a major hub for technology and innovation.'}\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.chat_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e521a1-60cc-432b-a254-44d501ad1178",
   "metadata": {},
   "source": [
    "| Feature             | `LLMChain`                        | `ConversationChain`                     |\n",
    "|---------------------|-----------------------------------|-----------------------------------------|\n",
    "| **Purpose**         | Single interactions, stateless tasks | Multi-turn conversations, context maintenance |\n",
    "| **Structure**       | Prompt + LLM                       | Prompt + LLM + Conversation history    |\n",
    "| **State**           | Stateless                          | Stateful (maintains conversation history) |\n",
    "| **Use Case**        | Text generation, classification, independent Q&A | Chatbots, conversational applications with context |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "92173a3b-e2d2-4b95-9ed2-f413965427d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "de63a99b-8687-418c-85d9-4611e260dd54",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(input_variables= [\"context\", \"input\"], \n",
    "                                 template       = \"{context}\\nUser: {input}\\nAI:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "753b6830-c6df-4edf-9e77-bcd505805bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLMChain with the LLM and template\n",
    "chain = LLMChain(llm   = llm, \n",
    "                 prompt= prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "49fa5176-f3d9-474d-acc4-87badb9769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty context\n",
    "context = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec00eaa9-2955-4396-806d-2d17585cd0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example interactions\n",
    "user_inputs = [\"What is the capital of France?\", \n",
    "               \"And its population?\", \n",
    "               \"What about Germany?\",\n",
    "               \"Compare the 2 citites in terms of job opportunities\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "03ef5ed7-384c-4e69-95dc-7a2fdf87406e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0510ff70-390d-4536-8dae-084ab06bc209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n",
      "{'context': '',\n",
      " 'input': 'What is the capital of France?',\n",
      " 'text': 'The capital of France is Paris.'}\n",
      "-----------------\n",
      "And its population?\n",
      "{'context': '\\n'\n",
      "            'User: What is the capital of France?\\n'\n",
      "            \"AI: {'context': '', 'input': 'What is the capital of France?', \"\n",
      "            \"'text': 'The capital of France is Paris.'}\",\n",
      " 'input': 'And its population?',\n",
      " 'text': \"{'context': '', 'input': 'And its population?', 'text': 'The \"\n",
      "         \"population of Paris is approximately 2.2 million people.'}\"}\n",
      "-----------------\n",
      "What about Germany?\n",
      "{'context': '\\n'\n",
      "            'User: What is the capital of France?\\n'\n",
      "            \"AI: {'context': '', 'input': 'What is the capital of France?', \"\n",
      "            \"'text': 'The capital of France is Paris.'}\\n\"\n",
      "            'User: And its population?\\n'\n",
      "            'AI: {\\'context\\': \"\\\\nUser: What is the capital of France?\\\\nAI: '\n",
      "            \"{'context': '', 'input': 'What is the capital of France?', \"\n",
      "            '\\'text\\': \\'The capital of France is Paris.\\'}\", \\'input\\': \\'And '\n",
      "            'its population?\\', \\'text\\': \"{\\'context\\': \\'\\', \\'input\\': '\n",
      "            \"'And its population?', 'text': 'The population of Paris is \"\n",
      "            'approximately 2.2 million people.\\'}\"}',\n",
      " 'input': 'What about Germany?',\n",
      " 'text': 'Germany has a population of approximately 82 million people.'}\n",
      "-----------------\n",
      "Compare the 2 citites in terms of job opportunities\n",
      "{'context': '\\n'\n",
      "            'User: What is the capital of France?\\n'\n",
      "            \"AI: {'context': '', 'input': 'What is the capital of France?', \"\n",
      "            \"'text': 'The capital of France is Paris.'}\\n\"\n",
      "            'User: And its population?\\n'\n",
      "            'AI: {\\'context\\': \"\\\\nUser: What is the capital of France?\\\\nAI: '\n",
      "            \"{'context': '', 'input': 'What is the capital of France?', \"\n",
      "            '\\'text\\': \\'The capital of France is Paris.\\'}\", \\'input\\': \\'And '\n",
      "            'its population?\\', \\'text\\': \"{\\'context\\': \\'\\', \\'input\\': '\n",
      "            \"'And its population?', 'text': 'The population of Paris is \"\n",
      "            'approximately 2.2 million people.\\'}\"}\\n'\n",
      "            'User: What about Germany?\\n'\n",
      "            \"AI: {'context': '\\\\nUser: What is the capital of France?\\\\nAI: \"\n",
      "            \"{\\\\'context\\\\': \\\\'\\\\', \\\\'input\\\\': \\\\'What is the capital of \"\n",
      "            \"France?\\\\', \\\\'text\\\\': \\\\'The capital of France is \"\n",
      "            \"Paris.\\\\'}\\\\nUser: And its population?\\\\nAI: {\\\\'context\\\\': \"\n",
      "            '\"\\\\\\\\nUser: What is the capital of France?\\\\\\\\nAI: '\n",
      "            \"{\\\\'context\\\\': \\\\'\\\\', \\\\'input\\\\': \\\\'What is the capital of \"\n",
      "            \"France?\\\\', \\\\'text\\\\': \\\\'The capital of France is \"\n",
      "            'Paris.\\\\\\'}\", \\\\\\'input\\\\\\': \\\\\\'And its population?\\\\\\', '\n",
      "            '\\\\\\'text\\\\\\': \"{\\\\\\'context\\\\\\': \\\\\\'\\\\\\', \\\\\\'input\\\\\\': \\\\\\'And '\n",
      "            \"its population?\\\\', \\\\'text\\\\': \\\\'The population of Paris is \"\n",
      "            'approximately 2.2 million people.\\\\\\'}\"}\\', \\'input\\': \\'What '\n",
      "            \"about Germany?', 'text': 'Germany has a population of \"\n",
      "            \"approximately 82 million people.'}\",\n",
      " 'input': 'Compare the 2 citites in terms of job opportunities',\n",
      " 'text': \"I'm sorry, I don't have that information. Would you like me to look \"\n",
      "         'it up for you?'}\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for user_input in user_inputs:\n",
    "    # Run the LLM chain, adding context\n",
    "    response = chain.invoke({\"context\": context, \"input\": user_input})\n",
    "    print(user_input)\n",
    "    pprint(response)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    # Update context with user input and LLM response\n",
    "    context += f\"\\nUser: {user_input}\\nAI: {response}\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ec1a6-1465-42b1-b16f-04179a1469d2",
   "metadata": {},
   "source": [
    "**Context Management**\n",
    "\n",
    "- using deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f8ea9dd2-34d4-46dc-b321-ae3192b40966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e7094cc1-311a-4e72-9c5a-05d2737ad0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM and prompt template\n",
    "llm = ChatOpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "55830528-0015-4c01-b007-ef3e25536446",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate(input_variables= [\"context\", \"input\"], \n",
    "                                 template       = \"{context}\\nUser: {input}\\nAI:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "dd0088a0-27c4-4d0f-8ad9-776f927be49a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LLMChain with the LLM and template\n",
    "chain = LLMChain(llm   = llm, \n",
    "                 prompt= prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdf52348-2eb0-4b63-ad26-845c3e6b1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example interactions\n",
    "user_inputs = [\"What is the capital of France?\", \n",
    "               \"And its population?\", \n",
    "               \"What about Germany?\",\n",
    "               \"Compare the 2 citites in terms of weather in general\",\n",
    "               \"Which city is bigger in geographical size?\"\n",
    "              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "0d2e814b-2dad-4d01-819d-e969e0a6e10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a deque for context management\n",
    "context = deque(maxlen=5)  # Keep the last 5 interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8aac763-fa7b-4c16-b2cb-198c4ff9c529",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(context):\n",
    "\n",
    "    #return \"\\n\".join(f\"User: {user_input}\\nAI: {llm_response}\" for user_input, llm_response in context)\n",
    "    \"\"\"Format the context from the deque into a string.\"\"\"\n",
    "    formatted_context = \"\"\n",
    "    for user_input, llm_response in context:\n",
    "        formatted_context += f\"User: {user_input}\\nAI: {llm_response}\\n\"\n",
    "    return formatted_context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "42dc9b26-d023-41a9-8112-8e81ddde1408",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is the capital of France?\n",
      "{'context': deque([], maxlen=5),\n",
      " 'input': 'What is the capital of France?',\n",
      " 'text': 'The capital of France is Paris.'}\n",
      "-----------------\n",
      "And its population?\n",
      "{'context': deque([('What is the capital of France?',\n",
      "                    'The capital of France is Paris.')],\n",
      "                  maxlen=5),\n",
      " 'input': 'And its population?',\n",
      " 'text': 'The population of Paris is approximately 2.2 million people.'}\n",
      "-----------------\n",
      "What about Germany?\n",
      "{'context': deque([('What is the capital of France?',\n",
      "                    'The capital of France is Paris.'),\n",
      "                   ('And its population?',\n",
      "                    'The population of Paris is approximately 2.2 million '\n",
      "                    'people.')],\n",
      "                  maxlen=5),\n",
      " 'input': 'What about Germany?',\n",
      " 'text': \"I'm sorry, I do not have that information.\"}\n",
      "-----------------\n",
      "Compare the 2 citites in terms of weather in general\n",
      "{'context': deque([('What is the capital of France?',\n",
      "                    'The capital of France is Paris.'),\n",
      "                   ('And its population?',\n",
      "                    'The population of Paris is approximately 2.2 million '\n",
      "                    'people.'),\n",
      "                   ('What about Germany?',\n",
      "                    \"I'm sorry, I do not have that information.\")],\n",
      "                  maxlen=5),\n",
      " 'input': 'Compare the 2 citites in terms of weather in general',\n",
      " 'text': \"I'm sorry, I do not have that information.\"}\n",
      "-----------------\n",
      "Which city is bigger in geographical size?\n",
      "{'context': deque([('What is the capital of France?',\n",
      "                    'The capital of France is Paris.'),\n",
      "                   ('And its population?',\n",
      "                    'The population of Paris is approximately 2.2 million '\n",
      "                    'people.'),\n",
      "                   ('What about Germany?',\n",
      "                    \"I'm sorry, I do not have that information.\"),\n",
      "                   ('Compare the 2 citites in terms of weather in general',\n",
      "                    \"I'm sorry, I do not have that information.\")],\n",
      "                  maxlen=5),\n",
      " 'input': 'Which city is bigger in geographical size?',\n",
      " 'text': \"I'm sorry, I do not have that information.\"}\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for user_input in user_inputs:\n",
    "     # Run the LLM chain with the formatted context\n",
    "    formatted_context = format_context(context)\n",
    "    \n",
    "    response = chain.invoke({\"context\": context, \"input\": user_input})\n",
    "    \n",
    "    print(user_input)\n",
    "    pprint(response)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    # Update context with the new interaction\n",
    "    context.append((user_input, response['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e60de7-21ca-47a3-af6d-0793c5d0cb8e",
   "metadata": {},
   "source": [
    "#### Using a Simple List for Context Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4170c812-e99d-4e3e-b9b6-00dbafc32fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "06b5b8b3-f717-465b-bff5-c690bad93c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM and prompt template\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"context\", \"input\"],\n",
    "    template=\"{context}\\nUser: {input}\\nAI:\"\n",
    ")\n",
    "\n",
    "# Initialize LLMChain with the LLM and template\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Example interactions\n",
    "user_inputs = [\n",
    "    \"What is the capital of France?\",\n",
    "    \"And its population?\",\n",
    "    \"What about Germany?\",\n",
    "    \"Compare the 2 cities in terms of weather in general\",\n",
    "    \"Which city is bigger in geographical size?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26df86be-f16d-457f-9200-11cde76cd441",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list for context management\n",
    "context = []  # Use a simple list to keep track of interactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2dbad4e7-33f6-49e7-b186-331b55df6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_context(context):\n",
    "    \"\"\"Format the context from the list into a string.\"\"\"\n",
    "    formatted_context = \"\"\n",
    "    for user_input, llm_response in context:\n",
    "        formatted_context += f\"User: {user_input}\\nAI: {llm_response}\\n\"\n",
    "    return formatted_context.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a746baaa-978b-4025-9572-17d70ddd0ff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: What is the capital of France?\n",
      "{'context': '',\n",
      " 'input': 'What is the capital of France?',\n",
      " 'text': 'The capital of France is Paris.'}\n",
      "-----------------\n",
      "User: And its population?\n",
      "{'context': 'User: What is the capital of France?\\n'\n",
      "            'AI: The capital of France is Paris.',\n",
      " 'input': 'And its population?',\n",
      " 'text': 'The population of Paris is approximately 2.2 million people.'}\n",
      "-----------------\n",
      "User: What about Germany?\n",
      "{'context': 'User: What is the capital of France?\\n'\n",
      "            'AI: The capital of France is Paris.\\n'\n",
      "            'User: And its population?\\n'\n",
      "            'AI: The population of Paris is approximately 2.2 million people.',\n",
      " 'input': 'What about Germany?',\n",
      " 'text': 'The capital of Germany is Berlin, and its population is around 3.7 '\n",
      "         'million people.'}\n",
      "-----------------\n",
      "User: Compare the 2 cities in terms of weather in general\n",
      "{'context': 'User: What is the capital of France?\\n'\n",
      "            'AI: The capital of France is Paris.\\n'\n",
      "            'User: And its population?\\n'\n",
      "            'AI: The population of Paris is approximately 2.2 million people.\\n'\n",
      "            'User: What about Germany?\\n'\n",
      "            'AI: The capital of Germany is Berlin, and its population is '\n",
      "            'around 3.7 million people.',\n",
      " 'input': 'Compare the 2 cities in terms of weather in general',\n",
      " 'text': 'Paris tends to have a milder and more temperate climate compared to '\n",
      "         'Berlin. Paris experiences mild winters and warm summers, while '\n",
      "         'Berlin has colder winters and warmer summers. Berlin also tends to '\n",
      "         'have more precipitation throughout the year compared to Paris.'}\n",
      "-----------------\n",
      "User: Which city is bigger in geographical size?\n",
      "{'context': 'User: What is the capital of France?\\n'\n",
      "            'AI: The capital of France is Paris.\\n'\n",
      "            'User: And its population?\\n'\n",
      "            'AI: The population of Paris is approximately 2.2 million people.\\n'\n",
      "            'User: What about Germany?\\n'\n",
      "            'AI: The capital of Germany is Berlin, and its population is '\n",
      "            'around 3.7 million people.\\n'\n",
      "            'User: Compare the 2 cities in terms of weather in general\\n'\n",
      "            'AI: Paris tends to have a milder and more temperate climate '\n",
      "            'compared to Berlin. Paris experiences mild winters and warm '\n",
      "            'summers, while Berlin has colder winters and warmer summers. '\n",
      "            'Berlin also tends to have more precipitation throughout the year '\n",
      "            'compared to Paris.',\n",
      " 'input': 'Which city is bigger in geographical size?',\n",
      " 'text': ' Berlin is bigger in geographical size compared to Paris. Berlin '\n",
      "         'covers an area of approximately 891 square kilometers, while Paris '\n",
      "         'covers an area of around 105 square kilometers.'}\n",
      "-----------------\n"
     ]
    }
   ],
   "source": [
    "for user_input in user_inputs:\n",
    "    # Run the LLM chain with the formatted context\n",
    "    formatted_context = format_context(context)\n",
    "\n",
    "    # Invoke the chain\n",
    "    response = chain.invoke({\"context\": formatted_context, \"input\": user_input})\n",
    "\n",
    "    print(f\"User: {user_input}\")\n",
    "    pprint(response)\n",
    "    print(\"-----------------\")\n",
    "\n",
    "    # Update context with the new interaction\n",
    "    context.append((user_input, response['text']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b2c48c-bdfc-420e-8feb-e3dba7329723",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4402cb21-fbf0-49b5-827a-e71142f10a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
