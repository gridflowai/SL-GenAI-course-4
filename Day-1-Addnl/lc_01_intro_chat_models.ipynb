{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7ab06e5-c462-4cd9-98b7-055c18b1253c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe7b5fe-2c65-4cf8-9284-6afd5dd04a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a145caf-2fa6-4f25-875e-d7b7ae8da834",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3fa41071-9b11-45ba-9be0-438dd84aaa24",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8950d891-8737-4977-a1c9-6a1cb83e9540",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install --upgrade langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec02b7e-76e5-45db-9449-827f6d005911",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "#### Chatmodels integration \n",
    "------------------------------------\n",
    "\n",
    "- **Large Language Models (LLMs)**:\n",
    "  - Powerful machine learning models adept at various language-related tasks, including:\n",
    "    - Text generation\n",
    "    - Translation\n",
    "    - Summarization\n",
    "    - Question answering\n",
    "  - Capable of performing these tasks without specific fine-tuning for each scenario.\n",
    "\n",
    "- **Chat Model Interface**:\n",
    "  - Commonly used to interact with modern LLMs.\n",
    "  - Accepts a list of messages as input and returns a single message as output.\n",
    "\n",
    "- **New Features in Chat Models**:\n",
    "  - **Tool Calling**:\n",
    "    - Many chat models now support a native tool-calling API.\n",
    "    - Allows the model to interact with external services, APIs, and databases.\n",
    "    - Useful for extracting structured information from unstructured data.\n",
    "    - Enables the creation of advanced applications with AI-driven interactions.\n",
    "\n",
    "  - **Structured Output**:\n",
    "    - Enables chat models to respond in specific formats, such as JSON.\n",
    "    - Useful for producing outputs that follow a predefined schema.\n",
    "\n",
    "  - **Multimodality**:\n",
    "    - Extends the modelâ€™s capabilities beyond text processing.\n",
    "    - Supports handling of diverse data types, including images, audio, and video, broadening the range of tasks it can perform.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479b58a3-6219-4300-862c-b7df58ee2808",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9ed56b3-a446-47c1-9a0f-54265d725f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b9771a0-f06c-441d-a206-01e1ebf3ba76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user question\n",
    "question = \"Which NFL team won the Super Bowl in the 2010 season?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3240187-080e-4cdf-8e1a-798a91eb7179",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Answer: \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b9b53c1b-326d-47ea-a663-f61158c12df2",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = PromptTemplate(\n",
    "        template       = template,\n",
    "        input_variables= ['question']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ebb7fc0-7a47-43d6-94c0-f9dff3198f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatOpenAI(\n",
    "                model_name='gpt-4o-mini'\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c376024-34f5-4f6e-99b0-7f40aecf6684",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(\n",
    "    prompt = prompt,\n",
    "    llm    = model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2c28e777-ba4a-4024-8595-33110d4ee601",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'Which NFL team won the Super Bowl in the 2010 season?', 'text': 'The New Orleans Saints won the Super Bowl in the 2010 season, specifically Super Bowl XLIV, which took place on February 7, 2010. They defeated the Indianapolis Colts with a score of 31-17.'}\n"
     ]
    }
   ],
   "source": [
    "print(llm_chain.invoke(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fc9f75-7ee2-41ac-8919-328b2381d843",
   "metadata": {},
   "source": [
    "#### multiple questions using generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f68b0a72-df7b-4ad6-893f-b76f73a5efc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qs = [\n",
    "    {'question': \"Which NFL team won the Super Bowl in the 2010 season?\"},\n",
    "    {'question': \"If I am 6 ft 4 inches, how tall am I in centimeters?\"},\n",
    "    {'question': \"Who was the 12th person on the moon?\"},\n",
    "    {'question': \"How many eyes does a blade of grass have?\"}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "82b7b33e-4988-435b-bb9f-21b9ab807155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[ChatGeneration(text='The New Orleans Saints won the Super Bowl in the 2010 season, defeating the Indianapolis Colts in Super Bowl XLIV.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The New Orleans Saints won the Super Bowl in the 2010 season, defeating the Indianapolis Colts in Super Bowl XLIV.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 27, 'total_tokens': 52, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-1d58343d-21c2-41a7-af65-575303401fc4-0', usage_metadata={'input_tokens': 27, 'output_tokens': 25, 'total_tokens': 52, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))], [ChatGeneration(text='To convert feet and inches to centimeters, you can use the following conversions:\\n\\n- 1 foot = 30.48 centimeters\\n- 1 inch = 2.54 centimeters\\n\\nFirst, convert your height to inches:\\n6 feet = 6 x 12 inches = 72 inches\\nAdding the extra 4 inches gives you:\\n72 inches + 4 inches = 76 inches\\n\\nNow, convert inches to centimeters:\\n76 inches x 2.54 centimeters/inch = 193.04 centimeters\\n\\nTherefore, if you are 6 feet 4 inches tall, you are approximately **193.04 centimeters** tall.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='To convert feet and inches to centimeters, you can use the following conversions:\\n\\n- 1 foot = 30.48 centimeters\\n- 1 inch = 2.54 centimeters\\n\\nFirst, convert your height to inches:\\n6 feet = 6 x 12 inches = 72 inches\\nAdding the extra 4 inches gives you:\\n72 inches + 4 inches = 76 inches\\n\\nNow, convert inches to centimeters:\\n76 inches x 2.54 centimeters/inch = 193.04 centimeters\\n\\nTherefore, if you are 6 feet 4 inches tall, you are approximately **193.04 centimeters** tall.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 127, 'prompt_tokens': 30, 'total_tokens': 157, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-c8c68f7c-f377-4b46-99b3-ad5afecbc827-0', usage_metadata={'input_tokens': 30, 'output_tokens': 127, 'total_tokens': 157, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))], [ChatGeneration(text='The 12th person to walk on the moon was Charles Duke. He served as the lunar module pilot for the Apollo 16 mission, which took place in April 1972.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The 12th person to walk on the moon was Charles Duke. He served as the lunar module pilot for the Apollo 16 mission, which took place in April 1972.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 24, 'total_tokens': 61, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-591d7cae-3018-4fc6-bb4d-5c9f0f8ce71b-0', usage_metadata={'input_tokens': 24, 'output_tokens': 37, 'total_tokens': 61, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))], [ChatGeneration(text='A blade of grass does not have any eyes. Grass is a plant and does not possess sensory organs like eyes.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='A blade of grass does not have any eyes. Grass is a plant and does not possess sensory organs like eyes.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 23, 'total_tokens': 46, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_0ba0d124f1', 'finish_reason': 'stop', 'logprobs': None}, id='run-bd967f22-c0f2-4528-b72b-43f3070348fb-0', usage_metadata={'input_tokens': 23, 'output_tokens': 23, 'total_tokens': 46, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}))]], llm_output={'token_usage': {'completion_tokens': 212, 'prompt_tokens': 104, 'total_tokens': 316, 'completion_tokens_details': {'audio_tokens': 0, 'reasoning_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini', 'system_fingerprint': 'fp_0ba0d124f1'}, run=[RunInfo(run_id=UUID('1d58343d-21c2-41a7-af65-575303401fc4')), RunInfo(run_id=UUID('c8c68f7c-f377-4b46-99b3-ad5afecbc827')), RunInfo(run_id=UUID('591d7cae-3018-4fc6-bb4d-5c9f0f8ce71b')), RunInfo(run_id=UUID('bd967f22-c0f2-4528-b72b-43f3070348fb'))], type='LLMResult')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generate LLM result from inputs\n",
    "result = llm_chain.generate(qs)\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208125c7-2bd6-4bd7-a3d5-bdbcc99bae23",
   "metadata": {},
   "source": [
    "#### Key Methods of a Chat Model\n",
    "\n",
    "- **invoke**: This is the main method used to interact with a chat model. It accepts a list of messages as input and produces a list of messages as output.\n",
    "- **stream**: This method enables the streaming of the chat model's output as it is being generated, allowing for real-time responses.\n",
    "- **batch**: This method allows for the batching of multiple requests to the chat model, improving processing efficiency by handling multiple inputs at once.\n",
    "- **bind_tools**: This method facilitates the binding of tools to the chat model, making them available within the execution context of the model.\n",
    "- **with_structured_output**: This is a wrapper around the invoke method designed for models that inherently support structured output, enhancing the output formatting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552634c-5854-48db-ba22-6ba5b5809226",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad238124-9e48-4d19-849e-084031aa815f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
