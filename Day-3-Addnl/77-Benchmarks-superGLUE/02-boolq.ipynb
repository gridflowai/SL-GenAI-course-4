{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a739c92c-eacd-498e-85e3-23cbcd8b845d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install adapter-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5a9423-4219-433a-92db-357047fded59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install -U adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e99fab-03a3-42d8-8f13-634880165350",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45dc4fc4-c34c-45b2-962c-ce5d37f85537",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd\n",
    "\n",
    "# Set display options for Pandas\n",
    "pd.set_option('display.max_colwidth', None)  # No truncation of column content\n",
    "pd.set_option('display.width', None)         # No truncation of DataFrame display width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad7c0eda-d0d1-4a2b-8fde-2fb42293c7ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load a specific SuperGLUE task (e.g., the BoolQ task for binary question answering)\n",
    "dataset = load_dataset('super_glue', 'boolq', trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2770609f-7ef6-4134-b8a2-9bfef9c0ca1c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 9427\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3270\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['question', 'passage', 'idx', 'label'],\n",
       "        num_rows: 3245\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bae0aa54-c499-4eb3-a8fa-08509e2e7c92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the train split to a pandas DataFrame\n",
    "train_df = pd.DataFrame(dataset['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cb8d946-6665-417f-9c92-3cd828c46a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9427, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c76faacd-156e-4d8d-9518-f55372aaee63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>passage</th>\n",
       "      <th>idx</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>can i use dexron iii for dexron ii</td>\n",
       "      <td>DEXRON -- In 1993, GM released new Dexron-III fluid (GM Spec GM6417M and later GMN10055). It is generally backward-compatible with transmissions using earlier Dexron fluids or Type-A/Suffix-A fluid. However this specification failed to address a number of issues concerning long term durability such as shear stability and fluid oxidation. Dexron-III underwent a number of iterations in an attempt to address various shortcomings but was eventually replaced by new thinking i.e. DEXRON-VI.</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2636</th>\n",
       "      <td>is the garden of gethsemane the same as the mount of olives</td>\n",
       "      <td>Gethsemane -- Gethsemane (Greek: Γεθσημανή, Gethsemane; Hebrew: גת שמנים‎‎, Gat Shmanim; Syriac: ܓܕܣܡܢ‎, Gaḏ Šmānê, lit. ``oil press'') is an urban garden at the foot of the Mount of Olives in Jerusalem, most famous as the place where Jesus prayed and his disciples slept the night before his crucifixion; i.e. the site recorded as where the agony in the garden took place.</td>\n",
       "      <td>2636</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>600</th>\n",
       "      <td>is there a season 2 of hunted on cinemax</td>\n",
       "      <td>Hunted (2012 TV series) -- In early 2015, Frank Spotnitz stated that the series--and spinoff--had been officially cancelled by Cinemax, though he and George were open to continuing the project if it were to be picked up by another network.</td>\n",
       "      <td>600</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8583</th>\n",
       "      <td>is harmony of the seas the biggest cruise ship in the world</td>\n",
       "      <td>MS Harmony of the Seas -- MS Harmony of the Seas is an Oasis-class cruise ship built by STX France at the Chantiers de l'Atlantique shipyard in Saint-Nazaire, France for Royal Caribbean International. With a gross tonnage of 226,963 GT, she is the second largest passenger ship in the world, surpassing her older sisters Oasis of the Seas and Allure of the Seas, but surpassed by her newer sister Symphony of the Seas.</td>\n",
       "      <td>8583</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>can you use wood bats in college baseball</td>\n",
       "      <td>College baseball -- Though a wood bat is legal in NCAA competition, players overwhelmingly prefer and use a metal bat. The metal bat was implemented in college baseball in 1975. Use of a metal bat is somewhat controversial. Supporters of an aluminum or composite bat note that it can increase offensive performance, as the speed of a ball off a metal bat is generally faster than off a wood bat. Those against metal, and for wood, argue that a metal bat is not safe to use, and that a metal bat doesn't prepare players for the next level, as professional baseball uses a wood bat exclusively. In the 2011 season the NCAA changed the requirements for a metal bat, reducing the maximum allowed exit speed in a way that is said to produce a feeling more like a wood bat. As a result, in 2011 there was a drop-off in overall ``long'' drives or home runs relative to past years.</td>\n",
       "      <td>1624</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                         question  \\\n",
       "109                            can i use dexron iii for dexron ii   \n",
       "2636  is the garden of gethsemane the same as the mount of olives   \n",
       "600                      is there a season 2 of hunted on cinemax   \n",
       "8583  is harmony of the seas the biggest cruise ship in the world   \n",
       "1624                    can you use wood bats in college baseball   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        passage  \\\n",
       "109                                                                                                                                                                                                                                                                                                                                                                                                   DEXRON -- In 1993, GM released new Dexron-III fluid (GM Spec GM6417M and later GMN10055). It is generally backward-compatible with transmissions using earlier Dexron fluids or Type-A/Suffix-A fluid. However this specification failed to address a number of issues concerning long term durability such as shear stability and fluid oxidation. Dexron-III underwent a number of iterations in an attempt to address various shortcomings but was eventually replaced by new thinking i.e. DEXRON-VI.   \n",
       "2636                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Gethsemane -- Gethsemane (Greek: Γεθσημανή, Gethsemane; Hebrew: גת שמנים‎‎, Gat Shmanim; Syriac: ܓܕܣܡܢ‎, Gaḏ Šmānê, lit. ``oil press'') is an urban garden at the foot of the Mount of Olives in Jerusalem, most famous as the place where Jesus prayed and his disciples slept the night before his crucifixion; i.e. the site recorded as where the agony in the garden took place.   \n",
       "600                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             Hunted (2012 TV series) -- In early 2015, Frank Spotnitz stated that the series--and spinoff--had been officially cancelled by Cinemax, though he and George were open to continuing the project if it were to be picked up by another network.   \n",
       "8583                                                                                                                                                                                                                                                                                                                                                                                                                                                                         MS Harmony of the Seas -- MS Harmony of the Seas is an Oasis-class cruise ship built by STX France at the Chantiers de l'Atlantique shipyard in Saint-Nazaire, France for Royal Caribbean International. With a gross tonnage of 226,963 GT, she is the second largest passenger ship in the world, surpassing her older sisters Oasis of the Seas and Allure of the Seas, but surpassed by her newer sister Symphony of the Seas.   \n",
       "1624  College baseball -- Though a wood bat is legal in NCAA competition, players overwhelmingly prefer and use a metal bat. The metal bat was implemented in college baseball in 1975. Use of a metal bat is somewhat controversial. Supporters of an aluminum or composite bat note that it can increase offensive performance, as the speed of a ball off a metal bat is generally faster than off a wood bat. Those against metal, and for wood, argue that a metal bat is not safe to use, and that a metal bat doesn't prepare players for the next level, as professional baseball uses a wood bat exclusively. In the 2011 season the NCAA changed the requirements for a metal bat, reducing the maximum allowed exit speed in a way that is said to produce a feeling more like a wood bat. As a result, in 2011 there was a drop-off in overall ``long'' drives or home runs relative to past years.   \n",
       "\n",
       "       idx  label  \n",
       "109    109      1  \n",
       "2636  2636      0  \n",
       "600    600      0  \n",
       "8583  8583      0  \n",
       "1624  1624      1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3b7bff8-61de-4d8d-a635-995f96facb75",
   "metadata": {},
   "source": [
    "- Labels: 0 for False and 1 for True.\n",
    "- The task is binary, so it's a binary classification problem.\n",
    "- The label corresponds to whether the answer to the question is consistent with the information in the passage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b4422b-79f8-4909-88f4-ea0e1278273d",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Using a model pre-trained on Boolq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "033ce9c6-2282-4d33-af39-aa33c2c47af1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2a22d7c8-0d98-4668-8447-799810b3653f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Use an existing model trained on BoolQ task\n",
    "model_name = \"bert-base-uncased\"  # You can try using a model trained specifically for BoolQ tasks\n",
    "\n",
    "access_token ='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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "57e6bc68-8463-4177-bb67-ddd6b2fd0263",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the model and tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", token=access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eff5fcec-92a1-4646-a71e-599a568bb6d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare a sample question and passage for BoolQ\n",
    "question = \"Does the President of the United States live in the White House?\"\n",
    "passage  = \"The White House is the official residence and workplace of the President of the United States.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "857fc2c8-ba42-4357-ab93-3eefdee2c1f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction: No\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the input\n",
    "inputs = tokenizer(question, passage, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "\n",
    "# Get model predictions\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits  = outputs.logits\n",
    "    \n",
    "    prediction = torch.argmax(logits, dim=-1).item()\n",
    "\n",
    "# Interpret the result\n",
    "answer = \"Yes\" if prediction == 1 else \"No\"\n",
    "print(f\"Prediction: {answer}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "18ca8b17-5d44-49bb-9deb-68ac6539487b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1afe4ef9954875a68573c3bab50747",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/6.57k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "164f7240329040659fd4a647b5ee10ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/3.69M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4bdbc39e17445d87d375a7f6df7e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.26M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de9b2988fb14de6a48cd6cd241e8153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/9427 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc99adf1c7294598a232fc137b7a80b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3270 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset and pre-trained model\n",
    "dataset = load_dataset(\"boolq\", split=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c03d758-a77d-402f-ad14-6c364196f039",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer', 'passage'],\n",
       "    num_rows: 3270\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e85b060-3c59-4bb3-a4ca-e9dd8ef1b798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>passage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>do c++ strings need to be null terminated</td>\n",
       "      <td>False</td>\n",
       "      <td>Most modern libraries replace C strings with a structure containing a 32-bit or larger length value (far more than were ever considered for length-prefixed strings), and often add another pointer, a reference count, and even a NUL to speed up conversion back to a C string! Memory is far larger now, such that if the addition of 3 (or 16, or more) bytes to each string is a real problem the software will have to be dealing with so many small strings that some other storage method will save even more memory (for instance there may be so many duplicates that a hash table will use less memory). Examples include the C++ Standard Template Library std::string , the Qt QString , the MFC CString , and the C-based implementation CFString from Core Foundation as well as its Objective-C sibling NSString from Foundation, both by Apple. More complex structures may also be used to store strings such as the rope.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>can a puerto rican resident vote for president</td>\n",
       "      <td>False</td>\n",
       "      <td>Voting rights of United States citizens in Puerto Rico, like the voting rights of residents of other United States territories, differ from those of United States citizens in each of the fifty states and the District of Columbia. Residents of Puerto Rico and other U.S. territories do not have voting representation in the United States Congress, and are not entitled to electoral votes for President. The United States Constitution grants congressional voting representation to U.S. states, which Puerto Rico and other U.S. territories are not, specifying that members of Congress shall be elected by direct popular vote and that the President and the Vice President shall be elected by electors chosen by the States.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1412</th>\n",
       "      <td>has brazil ever won the world cup in europe</td>\n",
       "      <td>True</td>\n",
       "      <td>Brazil is the most successful national team in the history of the World Cup, having won five titles, earning second-place, third-place and fourth-place finishes twice each. Brazil is one of the countries besides Argentina, Spain and Germany to win a FIFA World Cup away from its continent (Sweden 1958, Mexico 1970, USA 1994 and South Korea/Japan 2002). Brazil is the only national team to have played in all FIFA World Cup editions without any absence or need for playoffs. Brazil also has the best overall performance in World Cup history in both proportional and absolute terms with a record of 73 victories in 109 matches played, 124 goal difference, 237 points and only 18 losses.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1542</th>\n",
       "      <td>has an nhl team ever come back from 3-0</td>\n",
       "      <td>True</td>\n",
       "      <td>The following is the list of teams to overcome 3--1 series deficits by winning three straight games to win a best-of-seven playoff series. In the history of major North American pro sports, teams that were down 3--1 in the series came back and won the series 52 times, more than half of them were accomplished by National Hockey League (NHL) teams. Teams overcame 3--1 deficit in the final championship round eight times, six were accomplished by Major League Baseball (MLB) teams in the World Series. Teams overcoming 3--0 deficit by winning four straight games were accomplished five times, four times in the NHL and once in MLB.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>can beet juice show up in your urine</td>\n",
       "      <td>True</td>\n",
       "      <td>Beeturia is the passing of red or pink urine after eating beetroots or foods colored with beetroot extract or beetroot pigments. The color is caused by the excretion of betalain (betacyanin) pigments such as betanin. The coloring is highly variable between individuals and between different occasions, and can vary in intensity from invisible to strong. The pigment is sensitive to oxidative degradation under strongly acidic conditions. Therefore, the urine coloring depends on stomach acidity and dwell time as well as the presence of protecting substances such as oxalic acid. Beeturia is often associated with red or pink feces.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            question  answer  \\\n",
       "1248       do c++ strings need to be null terminated   False   \n",
       "498   can a puerto rican resident vote for president   False   \n",
       "1412     has brazil ever won the world cup in europe    True   \n",
       "1542         has an nhl team ever come back from 3-0    True   \n",
       "1155            can beet juice show up in your urine    True   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           passage  \n",
       "1248  Most modern libraries replace C strings with a structure containing a 32-bit or larger length value (far more than were ever considered for length-prefixed strings), and often add another pointer, a reference count, and even a NUL to speed up conversion back to a C string! Memory is far larger now, such that if the addition of 3 (or 16, or more) bytes to each string is a real problem the software will have to be dealing with so many small strings that some other storage method will save even more memory (for instance there may be so many duplicates that a hash table will use less memory). Examples include the C++ Standard Template Library std::string , the Qt QString , the MFC CString , and the C-based implementation CFString from Core Foundation as well as its Objective-C sibling NSString from Foundation, both by Apple. More complex structures may also be used to store strings such as the rope.  \n",
       "498                                                                                                                                                                                                 Voting rights of United States citizens in Puerto Rico, like the voting rights of residents of other United States territories, differ from those of United States citizens in each of the fifty states and the District of Columbia. Residents of Puerto Rico and other U.S. territories do not have voting representation in the United States Congress, and are not entitled to electoral votes for President. The United States Constitution grants congressional voting representation to U.S. states, which Puerto Rico and other U.S. territories are not, specifying that members of Congress shall be elected by direct popular vote and that the President and the Vice President shall be elected by electors chosen by the States.  \n",
       "1412                                                                                                                                                                                                                                 Brazil is the most successful national team in the history of the World Cup, having won five titles, earning second-place, third-place and fourth-place finishes twice each. Brazil is one of the countries besides Argentina, Spain and Germany to win a FIFA World Cup away from its continent (Sweden 1958, Mexico 1970, USA 1994 and South Korea/Japan 2002). Brazil is the only national team to have played in all FIFA World Cup editions without any absence or need for playoffs. Brazil also has the best overall performance in World Cup history in both proportional and absolute terms with a record of 73 victories in 109 matches played, 124 goal difference, 237 points and only 18 losses.  \n",
       "1542                                                                                                                                                                                                                                                                                       The following is the list of teams to overcome 3--1 series deficits by winning three straight games to win a best-of-seven playoff series. In the history of major North American pro sports, teams that were down 3--1 in the series came back and won the series 52 times, more than half of them were accomplished by National Hockey League (NHL) teams. Teams overcame 3--1 deficit in the final championship round eight times, six were accomplished by Major League Baseball (MLB) teams in the World Series. Teams overcoming 3--0 deficit by winning four straight games were accomplished five times, four times in the NHL and once in MLB.  \n",
       "1155                                                                                                                                                                                                                                                                                      Beeturia is the passing of red or pink urine after eating beetroots or foods colored with beetroot extract or beetroot pigments. The color is caused by the excretion of betalain (betacyanin) pigments such as betanin. The coloring is highly variable between individuals and between different occasions, and can vary in intensity from invisible to strong. The pigment is sensitive to oxidative degradation under strongly acidic conditions. Therefore, the urine coloring depends on stomach acidity and dwell time as well as the presence of protecting substances such as oxalic acid. Beeturia is often associated with red or pink feces.  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dataset).sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc6657dc-6657-40a9-ad3e-ff522373f843",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to get predictions and scores\n",
    "def get_prediction(question, passage):\n",
    "    # Tokenize the inputs\n",
    "    inputs = tokenizer(question, passage, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    \n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        prediction = torch.argmax(logits, dim=-1).item()\n",
    "        score = torch.softmax(logits, dim=-1).max().item()  # Confidence score (softmax probability)\n",
    "    \n",
    "    return prediction, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "00234ba4-d4f3-4986-a6d1-d8edbbc0f8d0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fa14323a-3a8f-4af4-9107-7199be1eb43c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Passage:  Calvin Edwin Ripken Jr. (born August 24, 1960), nicknamed ``The Iron Man'', is an American former baseball shortstop and third baseman who played 21 seasons in Major League Baseball (MLB) for the Baltimore Orioles (1981--2001). One of his position's most offensively productive players, Ripken compiled 3,184 hits, 431 home runs, and 1,695 runs batted in during his career, and he won two Gold Glove Awards for his defense. He was a 19-time All-Star and was twice named American League (AL) Most Valuable Player (MVP). Ripken holds the record for consecutive games played, 2,632, surpassing Lou Gehrig's streak of 2,130 that had stood for 56 years and that many deemed unbreakable. In 2007, he was elected into the National Baseball Hall of Fame in his first year of eligibility, and currently has the fourth highest voting percentage of all time (98.53%).\n",
      "Question: is cal ripken jr in the hall of fame\n",
      "Label: Yes\n",
      "Prediction: No\n",
      "Score: 0.5327\n",
      "--------------------------------------------------------------------------------\n",
      "Passage:  In psychology, relationship obsessive--compulsive disorder (ROCD) is a form of obsessive--compulsive disorder focusing on intimate relationships. Such obsessions can become extremely distressing and debilitating, having negative impacts on relationships functioning.\n",
      "Question: is there a disorder for being obsessed with someone\n",
      "Label: Yes\n",
      "Prediction: No\n",
      "Score: 0.5313\n",
      "--------------------------------------------------------------------------------\n",
      "Passage:  The crisis was documented by photographers, musicians, and authors, many hired during the Great Depression by the federal government. For instance, the Farm Security Administration hired numerous photographers to document the crisis. Artists such as Dorothea Lange were aided by having salaried work during the Depression. She captured what have become classic images of the dust storms and migrant families. Among her most well-known photographs is Destitute Pea Pickers in California. Mother of Seven Children, which depicted a gaunt-looking woman, Florence Owens Thompson, holding three of her children. This picture expressed the struggles of people caught by the Dust Bowl and raised awareness in other parts of the country of its reach and human cost. Decades later, Thompson disliked the boundless circulation of the photo and resented the fact she did not receive any money from its broadcast. Thompson felt it gave her the perception as a Dust Bowl ``Okie.''\n",
      "Question: did the dust bowl happen during the great depression\n",
      "Label: Yes\n",
      "Prediction: No\n",
      "Score: 0.5237\n",
      "--------------------------------------------------------------------------------\n",
      "Passage:  The Atlantic City Rail Terminal is Atlantic City, New Jersey's train station. It is the easternmost stop on the Atlantic City Line to and from Philadelphia. The station was also served by the Atlantic City Express Service (ACES) from 2009 until it was formally discontinued on March 9, 2012. The Atlantic City terminal is a 5-track, 3-platform terminal located inside of the Atlantic City Convention Center. The Atlantic City Line is a commuter train and runs daily all day.\n",
      "Question: is there a train station in atlantic city\n",
      "Label: Yes\n",
      "Prediction: No\n",
      "Score: 0.5385\n",
      "--------------------------------------------------------------------------------\n",
      "Passage:  Whether or not they were socially tolerated or accepted by any particular culture, the existence of intersex people was known to many ancient and pre-modern cultures. The Greek historian Diodorus Siculus wrote of ``hermaphroditus'' in the first century BCE that Hermaphroditus ``is born with a physical body which is a combination of that of a man and that of a woman'', and with supernatural properties.\n",
      "Question: can you be born with both female and male parts\n",
      "Label: Yes\n",
      "Prediction: No\n",
      "Score: 0.5438\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Shuffle dataset and pick random samples\n",
    "shuffled_dataset = dataset.shuffle()  # Shuffle dataset\n",
    "\n",
    "# Print results for 5 random validation samples\n",
    "for i in range(5):  # Display 5 random samples from the validation set\n",
    "    example = shuffled_dataset[i]\n",
    "    question = example['question']\n",
    "    passage  = example['passage']\n",
    "    label    = example['answer']\n",
    "    \n",
    "    # Get model prediction and score\n",
    "    prediction, score = get_prediction(question, passage)\n",
    "    \n",
    "    # Display the results\n",
    "    print(f\"Passage:  {passage}\")\n",
    "    print(f\"Question: {question}\")\n",
    "    print(f\"Label: {'Yes' if label == 1 else 'No'}\")\n",
    "    print(f\"Prediction: {'Yes' if prediction == 1 else 'No'}\")\n",
    "    print(f\"Score: {score:.4f}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5130f6-8524-4272-9b07-66f3d7b6cd94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
