{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79f11fa4-72a0-4d4b-8d65-fd72c0c59904",
   "metadata": {},
   "source": [
    "----------------------------\n",
    "#### pre-trained model for MRPC\n",
    "----------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d739427-becf-4d52-a9c0-4248f412f08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fad3b22b-c97e-420e-a085-88b88bf94cc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "token = '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'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53b4b25d-7bf6-4bf0-a7de-cfcfb584e9a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the MRPC fine-tuned model and tokenizer\n",
    "model_name = \"google-bert/bert-base-cased-finetuned-mrpc\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad8b2248-3039-452c-b4c1-97e5b6400cf5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46ad11768f2d4cc2b52a0f8700543444",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/433 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e535f8bc8dc4acab5f51790e4092956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/433M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98c843c8820146dabbb07f8d0dff463f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07f22a2eee5c4b68a8d791021c29019c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508f2f279e534688aeff0c9225855d2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model_name, tokenizer=model_name, token=token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8defe8e4-6c15-40ba-a0c1-5ac58ab2cf04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Example sentence pairs\n",
    "sentence1 = \"The quick brown fox jumps over the lazy dog.\"\n",
    "sentence2 = \"A lazy dog was jumped over by the quick brown fox.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "117c33c3-b783-4dc3-b9b0-488e1d09af71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.8648684024810791}]\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "result = classifier(f\"{sentence1} [SEP] {sentence2}\")\n",
    "\n",
    "# Print result\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a59ba2-9412-40fd-9e66-e0730ff36518",
   "metadata": {},
   "source": [
    "#### Load the MRPC Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59480c5a-8c80-471a-8a4e-9c31abd6c1a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1043dfdd-a328-45e5-8720-84fa6ff0a3b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0d6458a401461f96c01551902d7a51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/649k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79368e4b5dbd4350aab3830847254a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/75.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49faa79b91ba48fcaf3fe7627ab28c86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/308k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61280376db7542c3975572ce9b7b7896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/3668 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed8b1de440714fceace2619fa425f821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/408 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8546552a34a4642ba4e96d27512f1b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1725 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the MRPC dataset\n",
    "dataset = load_dataset(\"glue\", \"mrpc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36ee6b06-fdee-47e8-9bbb-96bf2d61f588",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Set display options for Pandas\n",
    "pd.set_option('display.max_colwidth', None)  # No truncation of column content\n",
    "pd.set_option('display.width', None)  # No truncation of DataFrame display width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2421a6c3-7948-4912-a44e-cb33bbdd2c14",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the train, validation, and test datasets to Pandas DataFrames\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "valid_df = pd.DataFrame(dataset[\"validation\"])\n",
    "test_df  = pd.DataFrame(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f651b58d-932a-435a-ae7e-f4a8131034a6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1667</th>\n",
       "      <td>The Dow Jones industrial average .DJI rose 41.61 points , or 0.44 percent , to 9,415.82 .</td>\n",
       "      <td>The Dow Jones rose 41.61 points Friday , a gain of 0.4 % for the day and 0.7 % for the week .</td>\n",
       "      <td>0</td>\n",
       "      <td>1856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>Smith said simply \" Oh , my God , \" in the seconds afterward , according to Weinshall .</td>\n",
       "      <td>In the seconds after the crash , she added , Captain Smith said simply , \" Oh my God . \"</td>\n",
       "      <td>1</td>\n",
       "      <td>3519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>Westfield , which owns Galleria in Morley , also will continue discussions about the other co-owned centres such as Knox City in Melbourne , half-owned by Deutsche Bank .</td>\n",
       "      <td>Westfield also will continue discussions over the other co-owned centres , such as Knox City in Melbourne , where Deutsche Bank owns a 50 per cent stake .</td>\n",
       "      <td>1</td>\n",
       "      <td>549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>The most recent was in 1998 , when Dr Barnett Slepian was killed in his home in Amherst , New York .</td>\n",
       "      <td>The most recent killing was in 1998 , when Dr. Barnett Slepian was shot and killed in his home in Amherst , N.Y.</td>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1375</th>\n",
       "      <td>The case is Illinois v. Telemarketing Associates , 01-1806 .</td>\n",
       "      <td>The case decided Monday centered around an Illinois fund-raiser , Telemarketing Associates .</td>\n",
       "      <td>0</td>\n",
       "      <td>1531</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                       sentence1  \\\n",
       "1667                                                                                   The Dow Jones industrial average .DJI rose 41.61 points , or 0.44 percent , to 9,415.82 .   \n",
       "3166                                                                                     Smith said simply \" Oh , my God , \" in the seconds afterward , according to Weinshall .   \n",
       "492   Westfield , which owns Galleria in Morley , also will continue discussions about the other co-owned centres such as Knox City in Melbourne , half-owned by Deutsche Bank .   \n",
       "1066                                                                        The most recent was in 1998 , when Dr Barnett Slepian was killed in his home in Amherst , New York .   \n",
       "1375                                                                                                                The case is Illinois v. Telemarketing Associates , 01-1806 .   \n",
       "\n",
       "                                                                                                                                                       sentence2  \\\n",
       "1667                                                               The Dow Jones rose 41.61 points Friday , a gain of 0.4 % for the day and 0.7 % for the week .   \n",
       "3166                                                                    In the seconds after the crash , she added , Captain Smith said simply , \" Oh my God . \"   \n",
       "492   Westfield also will continue discussions over the other co-owned centres , such as Knox City in Melbourne , where Deutsche Bank owns a 50 per cent stake .   \n",
       "1066                                            The most recent killing was in 1998 , when Dr. Barnett Slepian was shot and killed in his home in Amherst , N.Y.   \n",
       "1375                                                                The case decided Monday centered around an Illinois fund-raiser , Telemarketing Associates .   \n",
       "\n",
       "      label   idx  \n",
       "1667      0  1856  \n",
       "3166      1  3519  \n",
       "492       1   549  \n",
       "1066      1  1193  \n",
       "1375      0  1531  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e4f895-2b5b-4345-acf9-9254c00a9c48",
   "metadata": {},
   "source": [
    "- `sentence1`: The first sentence in the pair.\n",
    "- `sentence2`: The second sentence in the pair.\n",
    "- `label`: The label indicating if the sentences are paraphrases (1) or not (0).\n",
    "- `idx`: The index of the example (not always necessary but included in the dataset).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b978a36-f356-43fc-90db-76945e16d8af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3668, 4), (408, 4), (1725, 4))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, valid_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6112c199-114a-49a6-964a-397e8d0c2b59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "validation_data = dataset[\"validation\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e0d7f33-7107-4261-bff3-e33a179cea09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model pipeline\n",
    "model_name = \"google-bert/bert-base-cased-finetuned-mrpc\"\n",
    "classifier = pipeline(\"text-classification\", model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8dd88e86-3fbf-490c-b8f5-0e89bec3048e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "y_true = []\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1f87ab79-e856-4784-a3db-17cd064c203f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for example in validation_data:\n",
    "    sentence1 = example[\"sentence1\"]\n",
    "    sentence2 = example[\"sentence2\"]\n",
    "    label = example[\"label\"]  # Ground truth label\n",
    "    \n",
    "    # Perform inference\n",
    "    prediction      = classifier(f\"{sentence1} [SEP] {sentence2}\", truncation=True)\n",
    "    predicted_label = 1 if prediction[0][\"label\"] == \"LABEL_1\" else 0\n",
    "\n",
    "    y_true.append(label)\n",
    "    y_pred.append(predicted_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b8566e16-c64c-4a1a-84f0-4b6047c0c4d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.3162\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Not Paraphrase       0.32      1.00      0.48       129\n",
      "    Paraphrase       0.00      0.00      0.00       279\n",
      "\n",
      "      accuracy                           0.32       408\n",
      "     macro avg       0.16      0.50      0.24       408\n",
      "  weighted avg       0.10      0.32      0.15       408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Calculate metrics using sklearn\n",
    "accuracy  = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall    = recall_score(y_true, y_pred)\n",
    "f1        = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Not Paraphrase\", \"Paraphrase\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66546fc1-6122-4085-935c-6e1c1b61caaa",
   "metadata": {
    "tags": []
   },
   "source": [
    "another model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "33261660-3446-4f15-b2f8-959efda557c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_name = \"textattack/bert-base-uncased-MRPC\"\n",
    "model_name = \"textattack/roberta-base-MRPC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cfa01438-4511-4bca-bcda-667ed2c51ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f291b352ab534eb89a97993a6a2bb707",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/564 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a1a2b3ea55e45d5866bb9c421d60509",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at textattack/roberta-base-MRPC were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bdb60c141374ca18d6fa6c6bffbe697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efd3d92aea674d89995ff4c665158e4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f0e2b97f06a4f889f6491c92125d99b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "001219b91ed241db983250d96ea189d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/239 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "classifier = pipeline(\"text-classification\", model=model_name, tokenizer=model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "93a69191-86f9-4b69-bb32-d3a4dd5b0364",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "#y_true = []\n",
    "y_pred = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2a53479-d864-4153-b0bf-0eb93195db3b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He said the foodservice pie business doesn 't fit the company 's long-term growth strategy .\n",
      "\n",
      "\" The foodservice pie business does not fit our long-term growth strategy .\n",
      "\n",
      "{'label': 'LABEL_1', 'score': 0.9979925155639648} 1\n"
     ]
    }
   ],
   "source": [
    "for example in validation_data:\n",
    "    print(example[\"sentence1\"])\n",
    "    print()\n",
    "    print(example[\"sentence2\"])\n",
    "    print()\n",
    "          \n",
    "    pred       = classifier({\"text\": example[\"sentence1\"], \"text_pair\": example[\"sentence2\"]})\n",
    "    pred_label = 1 if pred[\"label\"] == \"LABEL_1\" else 0\n",
    "    print(pred, pred_label)\n",
    "    break;\n",
    "    \n",
    "    #pred       = classifier({\"text\": example[\"sentence1\"], \"text_pair\": example[\"sentence2\"]})[0][\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3a71cc69-9997-40e7-bc01-b24ca21b9534",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for example in validation_data:\n",
    "    pred       = classifier({\"text\": example[\"sentence1\"], \"text_pair\": example[\"sentence2\"]})\n",
    "    \n",
    "    pred_label = 1 if pred == \"LABEL_1\" else 0\n",
    "    \n",
    "    y_pred.append(pred_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ce8789e-e5e3-4c33-8534-a6a193b2be9f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Accuracy: 0.3162\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "Not Paraphrase       0.32      1.00      0.48       129\n",
      "    Paraphrase       0.00      0.00      0.00       279\n",
      "\n",
      "      accuracy                           0.32       408\n",
      "     macro avg       0.16      0.50      0.24       408\n",
      "  weighted avg       0.10      0.32      0.15       408\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculate metrics using sklearn\n",
    "accuracy  = accuracy_score(y_true, y_pred)\n",
    "precision = precision_score(y_true, y_pred)\n",
    "recall    = recall_score(y_true, y_pred)\n",
    "f1        = f1_score(y_true, y_pred)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_true, y_pred, target_names=[\"Not Paraphrase\", \"Paraphrase\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27db154-43cd-49ab-abfc-e58fb9173825",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
