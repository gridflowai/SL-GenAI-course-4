{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3da1dac9-250e-40ac-8314-1e02e504e726",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install transformer --user\n",
    "#!pip intall datasets --user\n",
    "#!pip install evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "90a8c7f0-48eb-42c8-b1c0-f2e80a58af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import evaluate  # New library for metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b16bede-9f1c-41a2-9dea-28bf2fe4adb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f241948e30d84bbb9ba441a95a8e9420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/35.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6ea253b4bb84563aad4185805ecba44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/251k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60412ad4db0f40d3b9b13539b37650b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/37.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a20d2d6024b4402953ebdc74f2c1e55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/37.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e492a80d58094f6788e9fc33320522ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e901221cab584ff48a5c1e2a2c08a505",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fa177173ab4b0a96d4a7343f012dff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the COLA dataset\n",
    "cola = load_dataset(\"glue\", \"cola\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8644180c-273d-4825-82e3-d68f13eaf163",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datasets.dataset_dict.DatasetDict"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cola)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a56dab1-6732-4868-b1f5-d1ab16ca7a24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['train', 'validation', 'test'])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef80831b-27ae-4754-91db-2723e124a7a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8551"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cola['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00569978-22e7-4805-9983-c893ad125c5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1043, 1063)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cola['validation']), len(cola['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec14f4fb-fb6f-4818-9140-77c4c715b56e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': \"I'll fix you a drink.\", 'label': 1, 'idx': 5}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cola['train'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "671ff61e-b030-499a-b91d-b51aa7d24079",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the train split\n",
    "train_data = cola[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1872d1b8-761b-4b0f-817a-c2e8caadc62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    6023\n",
       "0    2528\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Count the distribution of labels\n",
    "label_distribution = train_data.to_pandas()[\"label\"].value_counts()\n",
    "label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eda53d5-f80b-4022-aa8a-8c3af107989c",
   "metadata": {},
   "source": [
    "The label distribution in the CoLA training dataset is:\n",
    "\n",
    "- Label 1 (Acceptable): 6,023 samples\n",
    "- Label 0 (Unacceptable): 2,528 samples\n",
    "  \n",
    "This indicates that the dataset is imbalanced, with significantly more examples of acceptable sentences compared to unacceptable ones. The ratio is approximately 2.38:1 in favor of acceptable sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0885f402-f1d6-4eb8-a724-e7aa2dfcbaa0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained tokenizer and model\n",
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name,\n",
    "                                           cache_dir = r'D:\\AI-DATASETS\\07-Hugging-Face-Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6940771d-b423-4786-972d-f2b44573e727",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, \n",
    "                                                           num_labels=2,\n",
    "                                                           cache_dir = r'D:\\AI-DATASETS\\07-Hugging-Face-Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "27378dd3-5a06-4769-a25f-0a24b22a1fd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Prepare the validation data\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"sentence\"], padding=\"max_length\", truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f4319f8-5d42-4351-b027-e36e63e3b9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "656539813c4441f0beacda03cd46d7a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized_val = cola[\"validation\"].map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e4723841-c452-4345-ad4c-ce5baabb9431",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert tokenized dataset into PyTorch tensors (necessary for model input)\n",
    "val_dataset = tokenized_val.with_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "93f54635-a0d4-4f78-ab2d-fd06c5b43393",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define the evaluation metric\n",
    "metric = evaluate.load(\"matthews_correlation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42e132e3-54d0-409b-bf5a-4f297f0d0aef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "all_labels      = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c0c2fe4-764c-4d2d-8996-164e3e35ce8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56d26358-b3a2-414c-b252-f92a8ae4cc04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a DataLoader for the validation dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffca98cc-27ca-4bc1-b5e9-89471b12a75c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_dataloader = DataLoader(val_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f14883f8-794e-4e57-b2cf-57a7c6b4074a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in val_dataloader:\n",
    "        input_ids      = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        label          = batch[\"label\"]\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs     = model(input_ids, attention_mask=attention_mask)\n",
    "        logits      = outputs.logits\n",
    "        predictions = torch.argmax(logits, dim=-1).tolist()\n",
    "\n",
    "        all_predictions.append(predictions)\n",
    "        all_labels.append(label)\n",
    "        \n",
    "        break;\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2405fab3-dc1f-43a2-928a-4e69f88fe60b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1])]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb3592a8-3734-48d0-87dc-ac2e9c00a4b4",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "Original Text (before tokenization): \"The quick brown fox jumps over the lazy dog.\"\n",
    "\n",
    "After Tokenization (tokenized output):\n",
    "    \n",
    "{\n",
    "    'input_ids':      [101, 1996, 4248, 2829, 4419, 3598, 2058, 1996, 2552, 3899, 1997, 1996, 2821, 102],\n",
    "    'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
    "    'label': 1        # (or 0 if the sentence is grammatically incorrect)\n",
    "}\n",
    "```\n",
    "\n",
    "**Inference Process:**\n",
    "The inference process is done as follows:\n",
    "\n",
    "You feed the input_ids and attention_mask to the model.\n",
    "The model produces logits, which are unnormalized prediction scores for each class.\n",
    "You then apply argmax on the logits to get the predicted class.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab957b1c-8e26-4d5c-8c92-2bf3ff67977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the Matthew's Correlation Coefficient (MCC)\n",
    "mcc = metric.compute(predictions=all_predictions, references=all_labels)\n",
    "print(\"Matthew's Correlation Coefficient:\", mcc[\"matthews_correlation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110d085d-3192-4431-aae4-02c4defd1fa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013eaddd-1e6b-4898-99d4-97098bdcba06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "407f67e5-b7ac-47b0-b6a7-6ee2aea99623",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers_env",
   "language": "python",
   "name": "transformers_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
