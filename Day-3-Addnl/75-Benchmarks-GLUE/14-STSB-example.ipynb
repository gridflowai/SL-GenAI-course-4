{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60865e32-70a1-4a2a-9bd9-cde1e03f570f",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "#### STS-B dataset using the datasets library\n",
    "---------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f43f10ca-bda2-4d60-bcbc-d797d1411033",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c7919f9-27d9-4135-8861-3f9c00771fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c0efb8da8e04afe930e24968f5ada32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/502k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0646de7f08264e019c9d4e2ff50ee38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/151k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d615a6eddbc48e68eae80a2a0bba0df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "test-00000-of-00001.parquet:   0%|          | 0.00/114k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889d406c2bb74b769727f13d35bdf516",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/5749 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c4919c017424aeb8ac38b495e486963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/1500 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e950bbbd833044239bea4f66b4550160",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/1379 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the STS-B dataset\n",
    "dataset = load_dataset(\"glue\", \"stsb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a8bf3df7-c5df-4430-94f7-f7f56d6f2d70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the train and validation datasets into pandas DataFrames\n",
    "train_df      = pd.DataFrame(dataset['train'])\n",
    "validation_df = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdc51b73-fc45-4b1c-9379-eb127fdc82d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5749, 4), (1500, 4))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, validation_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfce8751-112a-4c15-9d09-9a99900d133f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>idx</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>Two dogs in a fenced kennel look ahead.</td>\n",
       "      <td>Two woman pose in a dining room with a baby.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5538</th>\n",
       "      <td>Iran's president condemns use of chemical weap...</td>\n",
       "      <td>Probe alleged use of chemical weapons in Syria</td>\n",
       "      <td>1.6</td>\n",
       "      <td>5538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>A man and a woman are kissing each other.</td>\n",
       "      <td>A man and a woman are talking to each other.</td>\n",
       "      <td>0.6</td>\n",
       "      <td>495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>There's no chance of a fair trial.</td>\n",
       "      <td>there is no chance at a fair trial.</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5102</th>\n",
       "      <td>East Ukraine Separatists Ask to Join Russia</td>\n",
       "      <td>Crimean Parliament Votes to Join Russia</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4476</th>\n",
       "      <td>China stock index futures close higher -- Dec. 4</td>\n",
       "      <td>China stock index futures close lower -- Jan. 24</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "1220            Two dogs in a fenced kennel look ahead.   \n",
       "5538  Iran's president condemns use of chemical weap...   \n",
       "495           A man and a woman are kissing each other.   \n",
       "2011                 There's no chance of a fair trial.   \n",
       "5102        East Ukraine Separatists Ask to Join Russia   \n",
       "4476   China stock index futures close higher -- Dec. 4   \n",
       "\n",
       "                                             sentence2  label   idx  \n",
       "1220      Two woman pose in a dining room with a baby.    0.0  1220  \n",
       "5538    Probe alleged use of chemical weapons in Syria    1.6  5538  \n",
       "495       A man and a woman are talking to each other.    0.6   495  \n",
       "2011               there is no chance at a fair trial.    5.0  2011  \n",
       "5102           Crimean Parliament Votes to Join Russia    2.8  5102  \n",
       "4476  China stock index futures close lower -- Jan. 24    2.2  4476  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.sample(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ad7fa0e-54b7-425d-b064-43af30914a3b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check for repetitions of sentence1\n",
    "repeated_sentences = train_df[train_df.duplicated(subset=['sentence1'], keep=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "438dd0b2-9ed6-4181-ad79-9282db15ad63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sort the repeated sentences first by sentence1, then by similarity score\n",
    "sorted_repeated_sentences = repeated_sentences.sort_values(by=['sentence1', 'label'], ascending=[True, False])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6aed1a2-5b02-4e34-99ec-fc3e83adce69",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>\"Fairies don't exist\" - fine.</td>\n",
       "      <td>\"Satyrs don't exist\" - fine.</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>\"Fairies don't exist\" - fine.</td>\n",
       "      <td>\"Leprechauns don't exist\" - fine.</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4829</th>\n",
       "      <td>10 dead, five injured in SW China road accident</td>\n",
       "      <td>1 dead, 39 injured in E China road accident</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>10 dead, five injured in SW China road accident</td>\n",
       "      <td>5 hurt in Gaza City car accident</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4861</th>\n",
       "      <td>17 killed, 133 wounded in bomb attacks in nort...</td>\n",
       "      <td>15 killed, 90 wounded in fresh attacks in Iraq</td>\n",
       "      <td>2.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>to repeat: They are NOT as sovereign as they w...</td>\n",
       "      <td>They are NOT as sovereign as they were before.</td>\n",
       "      <td>4.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1936</th>\n",
       "      <td>two puppies playing around in the grass</td>\n",
       "      <td>Two puppies play in the grass</td>\n",
       "      <td>5.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1679</th>\n",
       "      <td>two puppies playing around in the grass</td>\n",
       "      <td>Two dogs are wrestling in the grass.</td>\n",
       "      <td>4.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>you have no remains of a missile at the pentagon.</td>\n",
       "      <td>you have no witnesses for a missile at the pen...</td>\n",
       "      <td>2.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2406</th>\n",
       "      <td>you have no remains of a missile at the pentagon.</td>\n",
       "      <td>you have no remains of an A- at the pentagon.</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              sentence1  \\\n",
       "2035                      \"Fairies don't exist\" - fine.   \n",
       "2122                      \"Fairies don't exist\" - fine.   \n",
       "4829    10 dead, five injured in SW China road accident   \n",
       "4980    10 dead, five injured in SW China road accident   \n",
       "4861  17 killed, 133 wounded in bomb attacks in nort...   \n",
       "...                                                 ...   \n",
       "2284  to repeat: They are NOT as sovereign as they w...   \n",
       "1936            two puppies playing around in the grass   \n",
       "1679            two puppies playing around in the grass   \n",
       "2077  you have no remains of a missile at the pentagon.   \n",
       "2406  you have no remains of a missile at the pentagon.   \n",
       "\n",
       "                                              sentence2  label  \n",
       "2035                       \"Satyrs don't exist\" - fine.   1.20  \n",
       "2122                  \"Leprechauns don't exist\" - fine.   1.00  \n",
       "4829        1 dead, 39 injured in E China road accident   1.75  \n",
       "4980                   5 hurt in Gaza City car accident   1.00  \n",
       "4861     15 killed, 90 wounded in fresh attacks in Iraq   2.80  \n",
       "...                                                 ...    ...  \n",
       "2284     They are NOT as sovereign as they were before.   4.50  \n",
       "1936                      Two puppies play in the grass   5.00  \n",
       "1679               Two dogs are wrestling in the grass.   4.00  \n",
       "2077  you have no witnesses for a missile at the pen...   2.60  \n",
       "2406      you have no remains of an A- at the pentagon.   2.40  \n",
       "\n",
       "[540 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display sorted repeated sentence1 pairs\n",
    "sorted_repeated_sentences[['sentence1', 'sentence2', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "28d48709-f287-48f1-b6cf-1d067f00595c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8707309f-09ea-44cd-9b09-c70c1bc17347",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert the train dataset to pandas dataframe\n",
    "df = pd.DataFrame(dataset['validation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9c03548-a54e-492f-a8bc-5b5c18fef480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the pre-trained model for sentence embeddings\n",
    "model_name = \"sentence-transformers/bert-base-nli-mean-tokens\"\n",
    "tokenizer  = AutoTokenizer.from_pretrained(model_name)\n",
    "model      = AutoModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05a220b7-0f4f-401d-9e5f-d6b110bdead7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Function to compute sentence embeddings\n",
    "def get_sentence_embedding(sentence):\n",
    "    inputs = tokenizer(sentence, return_tensors='pt', padding=True, truncation=True, max_length=128)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        \n",
    "    sentence_embedding = outputs.last_hidden_state.mean(dim=1)\n",
    "    \n",
    "    return sentence_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8859eea5-c9d8-4825-b091-db8289588163",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Compute similarities\n",
    "true_scores      = []\n",
    "predicted_scores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "dabd9ac2-e3f4-4ebd-86f1-d09ad7abd05c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "402\n",
      "1467\n",
      "1479\n",
      "471\n",
      "663\n"
     ]
    }
   ],
   "source": [
    "for idx, row in df.sample(5).iterrows():\n",
    "    sentence1 = row['sentence1']\n",
    "    sentence2 = row['sentence2']\n",
    "    \n",
    "    true_score = row['label']                      # STS-B scores\n",
    "\n",
    "    # Get embeddings\n",
    "    embedding1 = get_sentence_embedding(sentence1)\n",
    "    embedding2 = get_sentence_embedding(sentence2)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(embedding1.numpy(), embedding2.numpy())[0][0]\n",
    "\n",
    "    # Normalize cosine similarity to match the STS-B scale (0–5)\n",
    "    normalized_score = similarity * 5             # Map [0, 1] to [0, 5]\n",
    "\n",
    "    true_scores.append(true_score)\n",
    "    predicted_scores.append(normalized_score)\n",
    "    \n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1c5559c7-a804-4786-9620-c485d83874f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([2.5999999046325684,\n",
       "  0.4000000059604645,\n",
       "  4.0,\n",
       "  2.200000047683716,\n",
       "  2.799999952316284],\n",
       " [3.9386707544326782,\n",
       "  3.2423135638237,\n",
       "  4.591420292854309,\n",
       "  3.765115737915039,\n",
       "  2.7710020542144775])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_scores, predicted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a1798e37-32bb-4629-b5e0-571db11b389f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 2.5341983940040365\n",
      "Pearson Correlation: 0.5546792500723023\n"
     ]
    }
   ],
   "source": [
    "# Evaluation metrics\n",
    "mse = mean_squared_error(true_scores, predicted_scores)\n",
    "pearson_corr, _ = pearsonr(true_scores, predicted_scores)\n",
    "\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"Pearson Correlation: {pearson_corr}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64506ec-3a5b-4671-8886-9a60d8884826",
   "metadata": {},
   "source": [
    "#### Challenges\n",
    "\n",
    "1. **Cosine Similarity Precision**  \n",
    "   - If embeddings are not robust, the cosine similarity may not fully reflect semantic similarity.\n",
    "\n",
    "2. **Human Judgment Variability**  \n",
    "   - Annotators in STS-B might rate sentences subjectively, which can make model evaluation noisy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac33f847-49ef-4955-bea5-976d158981d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
