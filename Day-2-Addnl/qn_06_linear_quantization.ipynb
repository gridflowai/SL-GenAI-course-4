{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "38ed5613-6553-4ca2-8e96-9511e1aa906d",
   "metadata": {},
   "source": [
    "#### Linear Quantization\n",
    "\n",
    "- **Definition**:\n",
    "  - Linear quantization is a technique used to map a large set of values (often continuous) to a smaller set of discrete values. This process is commonly used in digital signal processing, image processing, and machine learning to reduce the precision of data, making it more efficient to store and process.\n",
    "\n",
    "- **Process**:\n",
    "  1. **Range Definition**:\n",
    "     - Determine the range of the input values, typically by identifying the minimum and maximum values.\n",
    "     - Example: For an 8-bit unsigned integer, the range is usually [0, 255].\n",
    "  \n",
    "  2. **Quantization Levels**:\n",
    "     - Choose the number of discrete levels (quantization levels) to map the input values to.\n",
    "     - Example: An 8-bit quantization has 256 levels.\n",
    "\n",
    "  3. **Scale Factor**:\n",
    "     - Compute a scale factor that defines how the input range is mapped to the quantization levels.\n",
    "     - The formula for the scale factor \\( S \\) is: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85664084-ed84-4a93-9f2e-22d89cf8d762",
   "metadata": {},
   "source": [
    "\n",
    "$$ S = \\frac{\\text{max value} - \\text{min value}}{\\text{number of levels} - 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e6fdb83-2a15-4bc2-bf0e-6b2835377457",
   "metadata": {},
   "source": [
    "  4. **Mapping**:\n",
    "     - Each input value is then scaled and rounded to the nearest quantization level.\n",
    "     - The quantized value \\( Q(x) \\) for an input value \\( x \\) is calculated as:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda999a2-e736-4d31-ab22-0477b923f740",
   "metadata": {},
   "source": [
    "$$Q(x) = \\text{round}\\left(\\frac{x - \\text{min_value}}{S}\\right) \\times S + \\text{min_value}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117c8486-3b60-478a-acae-f8f5a494ce3a",
   "metadata": {},
   "source": [
    "**Example**:\n",
    "  - Suppose we want to quantize a set of floating-point values into 8-bit unsigned integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb2ff616-fc2c-47ab-8003-a0f5aa98ac1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "853852df-c69a-4e3b-bbbe-67af818172a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original floating-point values\n",
    "float_values = np.array([0.5, 0.8, 0.3, 0.9, 0.1])\n",
    "\n",
    "# Define the range for quantization (0 to 255 for 8-bit)\n",
    "min_value  = 0\n",
    "max_value  = 1\n",
    "num_levels = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f619acfa-ce9b-4ba2-b14c-c6bc7db97da9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original values: [0.5 0.8 0.3 0.9 0.1]\n",
      "Quantized values: [128 204  76 230  26]\n"
     ]
    }
   ],
   "source": [
    "# Compute the scale factor\n",
    "scale = (max_value - min_value) / (num_levels - 1)\n",
    "\n",
    "# Quantize the values\n",
    "quantized_values = np.round((float_values - min_value) / scale).astype(np.uint8)\n",
    "\n",
    "print(\"Original values:\", float_values)\n",
    "print(\"Quantized values:\", quantized_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3310b78e-2dd7-4bda-8b58-0931686ad0ad",
   "metadata": {},
   "source": [
    "**Observation**: The floating-point values are mapped to corresponding 8-bit integers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492c1654-8fcd-41b1-ae65-a7e4e7e09c80",
   "metadata": {},
   "source": [
    "- **Types of Quantization**:\n",
    "  - **Uniform Quantization**:\n",
    "    - The most straightforward form, where the quantization levels are evenly spaced across the range.\n",
    "  \n",
    "  - **Non-Uniform Quantization**:\n",
    "    - Uses non-linear mapping where quantization levels are not evenly spaced. This is useful in scenarios where certain ranges of the input are more important than others (e.g., logarithmic quantization).\n",
    "\n",
    "- **Applications**:\n",
    "  - **Digital Signal Processing**: Converting analog signals to digital by mapping the continuous amplitude of a signal to discrete levels.\n",
    "  - **Image Processing**: Reducing the number of colors in an image by mapping the original color values to a limited set of colors (color quantization).\n",
    "  - **Machine Learning**: Quantizing model parameters or activations to reduce memory usage and computational requirements, particularly in neural networks for edge devices.\n",
    "  \n",
    "- **Advantages**:\n",
    "  - **Memory and Storage Efficiency**: Reduces the size of the data by using fewer bits to represent it.\n",
    "  - **Faster Computation**: Lower precision data types can be processed faster, especially on hardware with limited resources.\n",
    "\n",
    "- **Disadvantages**:\n",
    "  - **Loss of Precision**: Quantization introduces errors due to the loss of detail when mapping to fewer levels.\n",
    "  - **Quantization Error**: The difference between the original value and the quantized value, which can accumulate and affect the quality of the output in processes like signal reconstruction.\n",
    "\n",
    "- **Quantization Error**:\n",
    "  - The difference between the original value and the quantized value is called quantization error. This error can be minimized by increasing the number of quantization levels, but this also increases the bit-width and storage requirements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b94be5-1c0a-4f48-83d6-3f7741cbbfcf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
